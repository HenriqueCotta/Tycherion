src
└── tycherion
    ├── adapters
    │   ├── mt5
    │   │   ├── __pycache__ (ignored)
    │   │   ├── >>> account_mt5.py <<<
    │   │   ├── >>> market_data_mt5.py <<<
    │   │   ├── >>> trading_mt5.py <<<
    │   │   └── >>> universe_mt5.py <<<
    │   └── observability
    │       ├── >>> __init__.py <<<
    │       ├── __pycache__ (ignored)
    │       ├── noop
    │       │   ├── >>> __init__.py <<<
    │       │   ├── __pycache__ (ignored)
    │       │   └── >>> noop_observability.py <<<
    │       └── otel
    │           ├── >>> __init__.py <<<
    │           ├── __pycache__ (ignored)
    │           ├── >>> console_dev.py <<<
    │           ├── >>> otel_export.py <<<
    │           ├── >>> otel_logs.py <<<
    │           ├── >>> otel_metrics.py <<<
    │           ├── >>> otel_observability.py <<<
    │           ├── >>> otel_resource.py <<<
    │           └── >>> otel_traces.py <<<
    ├── application
    │   ├── pipeline
    │   │   ├── >>> __init__.py <<<
    │   │   ├── __pycache__ (ignored)
    │   │   ├── >>> config.py <<<
    │   │   ├── >>> result.py <<<
    │   │   └── >>> service.py <<<
    │   ├── plugins
    │   │   ├── __pycache__ (ignored)
    │   │   └── >>> registry.py <<<
    │   ├── runmodes
    │   │   ├── __pycache__ (ignored)
    │   │   └── >>> live_multimodel.py <<<
    │   └── services
    │       ├── __pycache__ (ignored)
    │       ├── >>> coverage_selector.py <<<
    │       ├── >>> ensemble.py <<<
    │       ├── >>> order_planner.py <<<
    │       └── >>> sizer.py <<<
    ├── bootstrap
    │   ├── __pycache__ (ignored)
    │   └── >>> main.py <<<
    ├── domain
    │   ├── >>> __init__.py <<<
    │   ├── __pycache__ (ignored)
    │   ├── market
    │   │   ├── >>> __init__.py <<<
    │   │   ├── __pycache__ (ignored)
    │   │   └── >>> entities.py <<<
    │   ├── portfolio
    │   │   ├── >>> __init__.py <<<
    │   │   ├── __pycache__ (ignored)
    │   │   ├── allocators
    │   │   │   ├── >>> __init__.py <<<
    │   │   │   ├── __pycache__ (ignored)
    │   │   │   ├── >>> base.py <<<
    │   │   │   ├── >>> equal_weight.py <<<
    │   │   │   └── >>> proportional.py <<<
    │   │   ├── balancers
    │   │   │   ├── >>> __init__.py <<<
    │   │   │   ├── __pycache__ (ignored)
    │   │   │   ├── >>> base.py <<<
    │   │   │   └── >>> threshold.py <<<
    │   │   └── >>> entities.py <<<
    │   └── signals
    │       ├── >>> __init__.py <<<
    │       ├── __pycache__ (ignored)
    │       ├── >>> entities.py <<<
    │       ├── indicators
    │       │   ├── >>> __init__.py <<<
    │       │   ├── __pycache__ (ignored)
    │       │   ├── >>> base.py <<<
    │       │   ├── >>> stretch_zscore.py <<<
    │       │   ├── >>> trend_donchian.py <<<
    │       │   └── >>> volatility_atr.py <<<
    │       └── models
    │           ├── >>> __init__.py <<<
    │           ├── __pycache__ (ignored)
    │           ├── >>> base.py <<<
    │           ├── >>> mean_reversion.py <<<
    │           └── >>> trend_following.py <<<
    ├── ports
    │   ├── __pycache__ (ignored)
    │   ├── >>> account.py <<<
    │   ├── >>> market_data.py <<<
    │   ├── observability
    │   │   ├── >>> __init__.py <<<
    │   │   ├── __pycache__ (ignored)
    │   │   ├── >>> logs.py <<<
    │   │   ├── >>> metrics.py <<<
    │   │   ├── >>> observability.py <<<
    │   │   ├── >>> semconv.py <<<
    │   │   ├── >>> traces.py <<<
    │   │   └── >>> types.py <<<
    │   ├── >>> trading.py <<<
    │   └── >>> universe.py <<<
    └── shared
        ├── __pycache__ (ignored)
        ├── >>> config.py <<<
        └── >>> decorators.py <<<



--- tycherion\adapters\mt5\account_mt5.py:START ---
from __future__ import annotations

import MetaTrader5 as mt5

from tycherion.ports.account import AccountPort
from tycherion.domain.portfolio.entities import Position


class MT5Account(AccountPort):
    def is_demo(self) -> bool:
        ai = mt5.account_info()
        return bool(ai and ai.trade_mode == mt5.ACCOUNT_TRADE_MODE_DEMO)

    def balance(self) -> float:
        ai = mt5.account_info()
        return float(getattr(ai, "balance", 0.0) or 0.0)

    def equity(self) -> float:
        ai = mt5.account_info()
        return float(getattr(ai, "equity", 0.0) or 0.0)

    def positions(self) -> list[Position]:
        poss = mt5.positions_get()
        out: list[Position] = []
        if poss:
            for p in poss:
                out.append(
                    Position(
                        symbol=p.symbol,
                        quantity=float(getattr(p, "volume", 0.0) or 0.0),
                        price=float(getattr(p, "price_open", 0.0) or 0.0),
                    )
                )
        return out

--- tycherion\adapters\mt5\account_mt5.py:END ---

--- tycherion\adapters\mt5\market_data_mt5.py:START ---
from __future__ import annotations
from datetime import datetime, timezone
from typing import Dict
import pandas as pd
import MetaTrader5 as mt5
from tycherion.ports.market_data import MarketDataPort

_TF_MAP: Dict[str, int] = {
    "M1": mt5.TIMEFRAME_M1,
    "M5": mt5.TIMEFRAME_M5,
    "M15": mt5.TIMEFRAME_M15,
    "M30": mt5.TIMEFRAME_M30,
    "H1": mt5.TIMEFRAME_H1,
    "H4": mt5.TIMEFRAME_H4,
    "D1": mt5.TIMEFRAME_D1,
}

class MT5MarketData(MarketDataPort):
    def get_bars(self, symbol: str, timeframe: str, start: datetime, end: datetime) -> pd.DataFrame:
        tf = _TF_MAP.get(timeframe.upper())
        if tf is None:
            raise ValueError(f"Unsupported timeframe: {timeframe}")
        rates = mt5.copy_rates_range(
            symbol, tf,
            start.astimezone(timezone.utc),
            end.astimezone(timezone.utc)
        )
        if rates is None or len(rates) == 0:
            return pd.DataFrame(columns=["time","open","high","low","close","tick_volume","spread","real_volume"])
        df = pd.DataFrame(rates)
        df["time"] = pd.to_datetime(df["time"], unit="s", utc=True)
        return df
--- tycherion\adapters\mt5\market_data_mt5.py:END ---

--- tycherion\adapters\mt5\trading_mt5.py:START ---
from __future__ import annotations
from dataclasses import dataclass
from typing import Optional
import MetaTrader5 as mt5
from tycherion.ports.trading import TradingPort, TradeResult
from tycherion.shared.decorators import demo_only, logged
from tycherion.application.services.sizer import symbol_min_volume, volume_from_weight

@dataclass
class MT5Trader(TradingPort):
    dry_run: bool = True
    require_demo: bool = True
    deviation_points: int = 10
    volume_mode: str = "min"
    fixed_volume: float = 0.01

    def _resolve_volume(self, symbol: str, volume: Optional[float]) -> float:
        if volume is not None:
            return float(volume)
        return volume_from_weight(symbol, 1.0, self.volume_mode, self.fixed_volume)

    @logged
    @demo_only
    def market_buy(self, symbol: str, volume: Optional[float] = None) -> TradeResult:
        if self.dry_run:
            return TradeResult(True, 0, None, "DRY_RUN: buy skipped")
        if not mt5.symbol_select(symbol, True):
            return TradeResult(False, -1, None, f"symbol_select failed: {symbol}")
        tick = mt5.symbol_info_tick(symbol)
        if not tick:
            return TradeResult(False, -2, None, "missing tick")
        vol = self._resolve_volume(symbol, volume)
        if vol < symbol_min_volume(symbol):
            vol = symbol_min_volume(symbol)
        request = {
            "action": mt5.TRADE_ACTION_DEAL,
            "symbol": symbol,
            "type": mt5.ORDER_TYPE_BUY,
            "volume": vol,
            "price": tick.ask,
            "deviation": self.deviation_points,
            "type_time": mt5.ORDER_TIME_GTC,
            "type_filling": mt5.ORDER_FILLING_RETURN,
            "magic": 401,
            "comment": "tycherion-buy",
        }
        check = mt5.order_check(request)
        if not check or check.retcode != mt5.TRADE_RETCODE_DONE:
            return TradeResult(False, getattr(check, "retcode", -3), None, f"order_check failed: {check}")
        res = mt5.order_send(request)
        ok = bool(res and res.retcode in (mt5.TRADE_RETCODE_DONE, mt5.TRADE_RETCODE_PLACED))
        return TradeResult(ok, getattr(res, "retcode", -4), getattr(res, "order", None), str(res))

    @logged
    @demo_only
    def market_sell(self, symbol: str, volume: Optional[float] = None) -> TradeResult:
        if self.dry_run:
            return TradeResult(True, 0, None, "DRY_RUN: sell skipped")
        if not mt5.symbol_select(symbol, True):
            return TradeResult(False, -1, None, f"symbol_select failed: {symbol}")
        tick = mt5.symbol_info_tick(symbol)
        if not tick:
            return TradeResult(False, -2, None, "missing tick")
        vol = self._resolve_volume(symbol, volume)
        if vol < symbol_min_volume(symbol):
            vol = symbol_min_volume(symbol)
        request = {
            "action": mt5.TRADE_ACTION_DEAL,
            "symbol": symbol,
            "type": mt5.ORDER_TYPE_SELL,
            "volume": vol,
            "price": tick.bid,
            "deviation": self.deviation_points,
            "type_time": mt5.ORDER_TIME_GTC,
            "type_filling": mt5.ORDER_FILLING_RETURN,
            "magic": 401,
            "comment": "tycherion-sell",
        }
        check = mt5.order_check(request)
        if not check or check.retcode != mt5.TRADE_RETCODE_DONE:
            return TradeResult(False, getattr(check, "retcode", -3), None, f"order_check failed: {check}")
        res = mt5.order_send(request)
        ok = bool(res and res.retcode in (mt5.TRADE_RETCODE_DONE, mt5.TRADE_RETCODE_PLACED))
        return TradeResult(ok, getattr(res, "retcode", -4), getattr(res, "order", None), str(res))

--- tycherion\adapters\mt5\trading_mt5.py:END ---

--- tycherion\adapters\mt5\universe_mt5.py:START ---
from __future__ import annotations
import MetaTrader5 as mt5
from typing import List
from tycherion.ports.universe import UniversePort

class MT5Universe(UniversePort):
    def visible_symbols(self) -> List[str]:
        syms = mt5.symbols_get()
        return [s.name for s in syms if getattr(s, "visible", False)]

    def by_pattern(self, pattern: str) -> List[str]:
        syms = mt5.symbols_get(pattern)
        return [s.name for s in syms]

--- tycherion\adapters\mt5\universe_mt5.py:END ---

--- tycherion\adapters\observability\__init__.py:START ---

--- tycherion\adapters\observability\__init__.py:END ---

--- tycherion\adapters\observability\noop\noop_observability.py:START ---
from __future__ import annotations

from contextlib import contextmanager

from tycherion.ports.observability.logs import LoggerPort, LoggerProviderPort
from tycherion.ports.observability.metrics import CounterPort, MeterPort, MeterProviderPort
from tycherion.ports.observability.observability import ObservabilityPort
from tycherion.ports.observability.traces import SpanPort, TracerPort, TracerProviderPort
from tycherion.ports.observability.types import Attributes, Severity


class _NoopSpan(SpanPort):
    def set_attribute(self, key: str, value: object) -> None:
        return None

    def set_attributes(self, attributes: Attributes) -> None:
        return None

    def add_event(self, name: str, attributes: Attributes | None = None) -> None:
        return None

    def record_exception(self, exc: BaseException) -> None:
        return None

    def set_status_ok(self) -> None:
        return None

    def set_status_error(self, message: str | None = None) -> None:
        return None

    def is_recording(self) -> bool:
        return False


class _NoopTracer(TracerPort):
    @contextmanager
    def start_as_current_span(self, name: str, attributes: Attributes | None = None):
        yield _NoopSpan()


class _NoopTracerProvider(TracerProviderPort):
    def get_tracer(self, name: str, version: str | None = None) -> TracerPort:
        return _NoopTracer()


class _NoopLogger(LoggerPort):
    def emit(self, body: str, severity: Severity, attributes: Attributes | None = None) -> None:
        return None

    def is_enabled(self, severity: Severity) -> bool:
        return False


class _NoopLoggerProvider(LoggerProviderPort):
    def get_logger(self, name: str, version: str | None = None) -> LoggerPort:
        return _NoopLogger()


class _NoopCounter(CounterPort):
    def add(self, amount: int, attributes: Attributes | None = None) -> None:
        return None


class _NoopMeter(MeterPort):
    def create_counter(self, name: str, unit: str | None = None, description: str | None = None) -> CounterPort:
        return _NoopCounter()


class _NoopMeterProvider(MeterProviderPort):
    def get_meter(self, name: str, version: str | None = None) -> MeterPort:
        return _NoopMeter()


class NoopObservability(ObservabilityPort):
    def __init__(self) -> None:
        self._traces = _NoopTracerProvider()
        self._logs = _NoopLoggerProvider()
        self._metrics = _NoopMeterProvider()

    @property
    def traces(self) -> TracerProviderPort:
        return self._traces

    @property
    def logs(self) -> LoggerProviderPort:
        return self._logs

    @property
    def metrics(self) -> MeterProviderPort:
        return self._metrics

    def shutdown(self) -> None:
        return None

    def force_flush(self) -> None:
        return None

--- tycherion\adapters\observability\noop\noop_observability.py:END ---

--- tycherion\adapters\observability\noop\__init__.py:START ---

--- tycherion\adapters\observability\noop\__init__.py:END ---

--- tycherion\adapters\observability\otel\console_dev.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
import sys
from typing import Any, Mapping

from tycherion.ports.observability.types import Severity


@dataclass(slots=True)
class ConsoleConfig:
    enabled: bool = True
    min_severity: Severity = Severity.INFO
    show_span_lifecycle: bool = True


class ConsoleRenderer:
    def __init__(self, cfg: ConsoleConfig) -> None:
        self._cfg = cfg
        self._rank = {
            Severity.TRACE: 0,
            Severity.DEBUG: 10,
            Severity.INFO: 20,
            Severity.WARN: 30,
            Severity.ERROR: 40,
            Severity.FATAL: 50,
        }

    def enabled_for(self, sev: Severity) -> bool:
        if not self._cfg.enabled:
            return False
        return self._rank[sev] >= self._rank[self._cfg.min_severity]

    def _short(self, hex_id: str | None) -> str | None:
        if not hex_id:
            return None
        return hex_id[:8]

    def _ts(self) -> str:
        return datetime.now().strftime("%H:%M:%S")

    def _fmt_kv(self, attrs: Mapping[str, Any] | None) -> str:
        if not attrs:
            return ""
        items = []
        for k, v in attrs.items():
            if v is None:
                continue
            items.append(f"{k}={v}")
        return " ".join(items)

    def log(self, *, body: str, severity: Severity, attributes: Mapping[str, Any] | None, trace_id: str | None, span_id: str | None) -> None:
        if not self.enabled_for(severity):
            return
        meta = []
        if trace_id:
            meta.append(f"trace={trace_id if severity in (Severity.ERROR, Severity.FATAL) else self._short(trace_id)}")
        if span_id:
            meta.append(f"span={self._short(span_id)}")
        meta_s = (" | " + " ".join(meta)) if meta else ""
        attrs_s = self._fmt_kv(attributes)
        attrs_s = (attrs_s + " ") if attrs_s else ""
        line = f"{self._ts()} [{severity.value}] {attrs_s}{body}{meta_s}"
        print(line, file=sys.stdout)

    def span_started(self, *, name: str, attributes: Mapping[str, Any] | None, trace_id: str, span_id: str) -> None:
        if not (self._cfg.enabled and self._cfg.show_span_lifecycle):
            return
        meta = f"trace={self._short(trace_id)} span={self._short(span_id)}"
        attrs_s = self._fmt_kv(attributes)
        attrs_s = (attrs_s + " ") if attrs_s else ""
        print(f"{self._ts()} [SPAN] {attrs_s}{name} started | {meta}", file=sys.stdout)

    def span_ended(self, *, name: str, status: str, duration_ms: float | None, trace_id: str, span_id: str, error: bool) -> None:
        if not (self._cfg.enabled and self._cfg.show_span_lifecycle):
            return
        dur = f"{duration_ms:.1f}ms" if duration_ms is not None else "?"
        # If error, print full trace_id to make backend lookup easy.
        trace_meta = trace_id if error else self._short(trace_id)
        meta = f"trace={trace_meta} span={self._short(span_id)}"
        print(f"{self._ts()} [SPAN] {name} ended status={status} dur={dur} | {meta}", file=sys.stdout)

    def span_event(self, *, name: str, attributes: Mapping[str, Any] | None, trace_id: str | None, span_id: str | None) -> None:
        # Span events are usually info-ish, but we still respect min_severity (INFO).
        if not self.enabled_for(Severity.INFO):
            return
        meta = []
        if trace_id:
            # Span events don't carry severity. Keep output short by default.
            meta.append(f"trace={self._short(trace_id)}")
        if span_id:
            meta.append(f"span={self._short(span_id)}")
        meta_s = (" | " + " ".join(meta)) if meta else ""
        attrs_s = self._fmt_kv(attributes)
        attrs_s = (attrs_s + " ") if attrs_s else ""
        print(f"{self._ts()} [EVT] {attrs_s}{name}{meta_s}", file=sys.stdout)

--- tycherion\adapters\observability\otel\console_dev.py:END ---

--- tycherion\adapters\observability\otel\otel_export.py:START ---
from __future__ import annotations

from typing import Mapping


def _parse_headers(raw: str | Mapping[str, str] | None) -> dict[str, str]:
    if raw is None:
        return {}
    if isinstance(raw, Mapping):
        return {str(k).strip(): str(v).strip() for k, v in raw.items() if str(k).strip()}

    parsed: dict[str, str] = {}
    for part in str(raw).split(","):
        if not part.strip():
            continue
        if "=" in part:
            k, v = part.split("=", 1)
        elif ":" in part:
            k, v = part.split(":", 1)
        else:
            continue
        k = k.strip()
        v = v.strip()
        if k:
            parsed[k] = v
    return parsed


def _infer_insecure(endpoint: str, insecure: bool | None) -> bool:
    if insecure is not None:
        return bool(insecure)
    return not str(endpoint).lower().startswith("https://")


def build_span_exporter(endpoint: str, protocol: str, headers: str | Mapping[str, str] | None, insecure: bool | None = None):
    proto = (protocol or "grpc").strip().lower()
    hdrs = _parse_headers(headers)
    try:
        if proto == "http":
            from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter  # type: ignore

            return OTLPSpanExporter(endpoint=endpoint, headers=hdrs)

        from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter  # type: ignore

        return OTLPSpanExporter(endpoint=endpoint, headers=hdrs, insecure=_infer_insecure(endpoint, insecure))
    except Exception as exc:
        print(f"[tycherion] OTLP span exporter init failed: {exc}")
        return None


def build_metric_reader(
    *,
    endpoint: str,
    protocol: str,
    headers: str | Mapping[str, str] | None,
    insecure: bool | None = None,
):
    proto = (protocol or "grpc").strip().lower()
    hdrs = _parse_headers(headers)
    try:
        if proto == "http":
            from opentelemetry.exporter.otlp.proto.http.metric_exporter import OTLPMetricExporter  # type: ignore
            from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader  # type: ignore

            exporter = OTLPMetricExporter(endpoint=endpoint, headers=hdrs)
            return PeriodicExportingMetricReader(exporter)

        from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter  # type: ignore
        from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader  # type: ignore

        exporter = OTLPMetricExporter(endpoint=endpoint, headers=hdrs, insecure=_infer_insecure(endpoint, insecure))
        return PeriodicExportingMetricReader(exporter)
    except Exception as exc:
        print(f"[tycherion] OTLP metric exporter init failed: {exc}")
        return None

--- tycherion\adapters\observability\otel\otel_export.py:END ---

--- tycherion\adapters\observability\otel\otel_logs.py:START ---
from __future__ import annotations

from datetime import datetime, timezone
from typing import Any

from opentelemetry import trace as otel_trace  # type: ignore

from tycherion.adapters.observability.otel.console_dev import ConsoleRenderer
from tycherion.ports.observability import semconv
from tycherion.ports.observability.logs import LoggerPort, LoggerProviderPort
from tycherion.ports.observability.types import Attributes, Severity


def _current_trace_span_ids() -> tuple[str | None, str | None]:
    try:
        span = otel_trace.get_current_span()
        ctx = span.get_span_context()
        if not getattr(ctx, "is_valid", False):
            return None, None
        trace_id = format(int(ctx.trace_id), "032x")
        span_id = format(int(ctx.span_id), "016x")
        return trace_id, span_id
    except Exception:
        return None, None


class OtelLogger(LoggerPort):
    def __init__(
        self,
        *,
        schema_version: str,
        min_severity: Severity,
        console: ConsoleRenderer,
        format: str = "pretty",  # pretty | json
        allowed_channels: set[str] | None = None,
        logger_name: str | None = None,
    ) -> None:
        self._schema_version = schema_version
        self._min_severity = min_severity
        self._console = console
        self._format = (format or "pretty").lower()
        self._allowed_channels = allowed_channels or None
        self._logger_name = logger_name
        self._rank = {
            Severity.TRACE: 0,
            Severity.DEBUG: 10,
            Severity.INFO: 20,
            Severity.WARN: 30,
            Severity.ERROR: 40,
            Severity.FATAL: 50,
        }

    def is_enabled(self, severity: Severity) -> bool:
        return self._rank[severity] >= self._rank[self._min_severity]

    def emit(self, body: str, severity: Severity, attributes: Attributes | None = None) -> None:
        if not self.is_enabled(severity):
            return

        trace_id, span_id = _current_trace_span_ids()

        attrs: dict[str, Any] = dict(attributes or {})
        attrs[semconv.TYCHERION_SCHEMA_VERSION] = self._schema_version
        if self._logger_name:
            attrs.setdefault("tycherion.logger", self._logger_name)

        channel = attrs.get(semconv.ATTR_CHANNEL)
        if self._allowed_channels is not None:
            if channel is None:
                return
            if str(channel) not in self._allowed_channels:
                return

        if self._format == "json":
            payload = {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "severity": severity.value,
                "body": body,
                "attributes": attrs,
                "trace_id": trace_id,
                "span_id": span_id,
            }
            try:
                import json

                print(json.dumps(payload, ensure_ascii=False))
            except Exception:
                # fallback to console if JSON fails
                self._console.log(
                    body=body,
                    severity=severity,
                    attributes=attrs,
                    trace_id=trace_id,
                    span_id=span_id,
                )
        else:
            self._console.log(
                body=body,
                severity=severity,
                attributes=attrs,
                trace_id=trace_id,
                span_id=span_id,
            )


class OtelLoggerProvider(LoggerProviderPort):
    def __init__(
        self,
        *,
        schema_version: str,
        min_severity: Severity,
        console: ConsoleRenderer,
        format: str = "pretty",
        allowed_channels: set[str] | None = None,
    ) -> None:
        self._schema_version = schema_version
        self._min_severity = min_severity
        self._console = console
        self._format = format
        self._allowed_channels = allowed_channels

    def get_logger(self, name: str, version: str | None = None) -> LoggerPort:
        _ = (name, version)
        return OtelLogger(
            schema_version=self._schema_version,
            min_severity=self._min_severity,
            console=self._console,
            format=self._format,
            allowed_channels=self._allowed_channels,
            logger_name=name or None,
        )

--- tycherion\adapters\observability\otel\otel_logs.py:END ---

--- tycherion\adapters\observability\otel\otel_metrics.py:START ---
from __future__ import annotations

from typing import Any

from tycherion.ports.observability.metrics import CounterPort, MeterPort, MeterProviderPort
from tycherion.ports.observability.types import Attributes


class _OtelCounter(CounterPort):
    def __init__(self, counter: Any) -> None:
        self._counter = counter

    def add(self, amount: int, attributes: Attributes | None = None) -> None:
        try:
            self._counter.add(amount, attributes=dict(attributes or {}))
        except Exception:
            return None


class _OtelMeter(MeterPort):
    def __init__(self, meter: Any) -> None:
        self._meter = meter

    def create_counter(self, name: str, unit: str | None = None, description: str | None = None) -> CounterPort:
        try:
            c = self._meter.create_counter(name, unit=unit, description=description)
            return _OtelCounter(c)
        except Exception:
            # Fallback: no-op counter
            return _OtelCounter(counter=_NoopCounter())


class _NoopCounter:
    def add(self, amount: int, attributes: dict | None = None) -> None:
        return None


class OtelMeterProvider(MeterProviderPort):
    def __init__(self, provider: Any) -> None:
        self._provider = provider

    def get_meter(self, name: str, version: str | None = None) -> MeterPort:
        # opentelemetry-python uses instrumentation scope params; keyword names
        # differ across versions. Use positional for maximum compatibility.
        meter = self._provider.get_meter(name, version)
        return _OtelMeter(meter)

--- tycherion\adapters\observability\otel\otel_metrics.py:END ---

--- tycherion\adapters\observability\otel\otel_observability.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from typing import Any

from tycherion.adapters.observability.otel.console_dev import ConsoleConfig, ConsoleRenderer
from tycherion.adapters.observability.otel.otel_export import build_metric_reader, build_span_exporter
from tycherion.adapters.observability.otel.otel_resource import build_resource
from tycherion.adapters.observability.otel.otel_logs import OtelLoggerProvider
from tycherion.adapters.observability.otel.otel_metrics import OtelMeterProvider
from tycherion.adapters.observability.otel.otel_traces import OtelTracerProvider
from tycherion.ports.observability.observability import ObservabilityPort
from tycherion.ports.observability.traces import TracerProviderPort
from tycherion.ports.observability.logs import LoggerProviderPort
from tycherion.ports.observability.metrics import MeterProviderPort
from tycherion.ports.observability.types import Severity


@dataclass(slots=True)
class OtelObservabilityConfig:
    runner_id: str
    run_id: str
    schema_version: str

    deployment_env: str | None = None

    # Console output (dev-only)
    console_enabled: bool = True
    console_min_severity: Severity = Severity.INFO
    console_show_span_lifecycle: bool = True
    log_format: str = "pretty"  # pretty | json
    console_channels: set[str] | None = None

    # OTLP (Collector/Alloy)
    otlp_enabled: bool = False
    otlp_endpoint: str = "http://localhost:4317"
    otlp_protocol: str = "grpc"  # grpc | http
    otlp_headers: dict[str, str] | str | None = None
    otlp_insecure: bool | None = None  # None => infer from scheme (http->True, https->False)


class OtelObservability(ObservabilityPort):
    def __init__(self, cfg: OtelObservabilityConfig) -> None:
        self._cfg = cfg

        self._console = ConsoleRenderer(
            ConsoleConfig(
                enabled=bool(cfg.console_enabled),
                min_severity=cfg.console_min_severity,
                show_span_lifecycle=bool(cfg.console_show_span_lifecycle),
            )
        )
        allowed_channels = set(cfg.console_channels) if cfg.console_channels else None

        try:
            from opentelemetry import metrics as otel_metrics_api  # type: ignore
            from opentelemetry import trace as otel_trace  # type: ignore
            from opentelemetry.sdk.trace import TracerProvider  # type: ignore
            from opentelemetry.sdk.trace.export import BatchSpanProcessor  # type: ignore
            from opentelemetry.sdk.metrics import MeterProvider  # type: ignore
        except Exception as e:
            raise RuntimeError(
                "OtelObservability requires `opentelemetry-sdk` to be installed. "
                "Install project dependencies (see requirements/pyproject)."
            ) from e

        resource = build_resource(
            runner_id=cfg.runner_id,
            run_id=cfg.run_id,
            schema_version=cfg.schema_version,
            deployment_env=cfg.deployment_env,
        )

        tracer_provider = TracerProvider(resource=resource)

        if cfg.otlp_enabled:
            span_exporter = build_span_exporter(cfg.otlp_endpoint, cfg.otlp_protocol, cfg.otlp_headers, cfg.otlp_insecure)
            if span_exporter is not None:
                tracer_provider.add_span_processor(BatchSpanProcessor(span_exporter))

        try:
            otel_trace.set_tracer_provider(tracer_provider)
        except Exception:
            pass

        self._sdk_tracer_provider = tracer_provider
        self._traces = OtelTracerProvider(
            tracer_provider,
            schema_version=cfg.schema_version,
            console=self._console,
        )

        metric_reader = None
        if cfg.otlp_enabled:
            metric_reader = build_metric_reader(
                endpoint=cfg.otlp_endpoint,
                protocol=cfg.otlp_protocol,
                headers=cfg.otlp_headers,
                insecure=cfg.otlp_insecure,
            )

        if metric_reader is not None:
            meter_provider = MeterProvider(resource=resource, metric_readers=[metric_reader])
        else:
            meter_provider = MeterProvider(resource=resource)

        try:
            otel_metrics_api.set_meter_provider(meter_provider)
        except Exception:
            pass

        self._sdk_meter_provider = meter_provider
        self._metrics = OtelMeterProvider(meter_provider)

        self._logs = OtelLoggerProvider(
            schema_version=cfg.schema_version,
            min_severity=cfg.console_min_severity,
            console=self._console,
            format=cfg.log_format,
            allowed_channels=allowed_channels,
        )

    @property
    def traces(self) -> TracerProviderPort:
        return self._traces

    @property
    def logs(self) -> LoggerProviderPort:
        return self._logs

    @property
    def metrics(self) -> MeterProviderPort:
        return self._metrics

    def force_flush(self) -> None:
        try:
            self._sdk_tracer_provider.force_flush()
        except Exception:
            pass
        try:
            if self._sdk_meter_provider is not None:
                self._sdk_meter_provider.force_flush()
        except Exception:
            pass

    def shutdown(self) -> None:
        try:
            self.force_flush()
        finally:
            try:
                self._sdk_tracer_provider.shutdown()
            except Exception:
                pass
            try:
                if self._sdk_meter_provider is not None:
                    self._sdk_meter_provider.shutdown()
            except Exception:
                pass

--- tycherion\adapters\observability\otel\otel_observability.py:END ---

--- tycherion\adapters\observability\otel\otel_resource.py:START ---
from __future__ import annotations

from typing import Mapping

from tycherion.ports.observability import semconv


def build_resource(
    *,
    runner_id: str,
    run_id: str,
    schema_version: str,
    deployment_env: str | None = None,
):
    """Best-effort builder for the OpenTelemetry Resource used by Tycherion."""

    try:
        from opentelemetry.sdk.resources import Resource  # type: ignore
    except Exception as e:  # pragma: no cover - dependency missing is handled by caller
        raise RuntimeError("opentelemetry-sdk is required for OTel resource creation") from e

    attrs: Mapping[str, str] = {
        semconv.SERVICE_NAME: "tycherion",
        semconv.SERVICE_INSTANCE_ID: runner_id,
        semconv.TYCHERION_RUNNER_ID: runner_id,
        semconv.TYCHERION_RUN_ID: run_id,
        semconv.TYCHERION_SCHEMA_VERSION: schema_version,
    }

    if deployment_env:
        attrs = dict(attrs)
        attrs[semconv.DEPLOYMENT_ENVIRONMENT] = deployment_env

    return Resource.create(attrs)

--- tycherion\adapters\observability\otel\otel_resource.py:END ---

--- tycherion\adapters\observability\otel\otel_traces.py:START ---
from __future__ import annotations

import time
from contextlib import contextmanager
from typing import Any

from opentelemetry import trace as otel_trace  # type: ignore
from opentelemetry.trace.status import Status, StatusCode  # type: ignore

from tycherion.adapters.observability.otel.console_dev import ConsoleRenderer
from tycherion.ports.observability import semconv
from tycherion.ports.observability.traces import SpanPort, TracerPort, TracerProviderPort
from tycherion.ports.observability.types import Attributes


def _hex_trace_id(span_or_ctx: Any) -> str | None:
    try:
        ctx = span_or_ctx.get_span_context()
        if not getattr(ctx, "is_valid", False):
            return None
        return format(int(ctx.trace_id), "032x")
    except Exception:
        return None


def _hex_span_id(span_or_ctx: Any) -> str | None:
    try:
        ctx = span_or_ctx.get_span_context()
        if not getattr(ctx, "is_valid", False):
            return None
        return format(int(ctx.span_id), "016x")
    except Exception:
        return None


class OtelSpan(SpanPort):
    def __init__(
        self,
        span: Any,
        *,
        schema_version: str,
        console: ConsoleRenderer,
    ) -> None:
        self._span = span
        self._schema_version = schema_version
        self._console = console

        self._trace_id_hex = _hex_trace_id(span) or None
        self._span_id_hex = _hex_span_id(span) or None
        self._start_ns = time.time_ns()
        self._status = "UNSET"

    @property
    def trace_id_hex(self) -> str | None:
        return self._trace_id_hex

    @property
    def span_id_hex(self) -> str | None:
        return self._span_id_hex

    @property
    def status(self) -> str:
        return self._status

    @property
    def start_ns(self) -> int:
        return self._start_ns

    def set_attribute(self, key: str, value: object) -> None:
        try:
            self._span.set_attribute(key, value)
        except Exception:
            return None

    def set_attributes(self, attributes: Attributes) -> None:
        for k, v in (attributes or {}).items():
            self.set_attribute(k, v)

    def _decorate_event_attrs(self, attributes: Attributes | None) -> dict[str, Any]:
        attrs: dict[str, Any] = dict(attributes or {})
        attrs[semconv.TYCHERION_SCHEMA_VERSION] = self._schema_version
        return attrs

    def add_event(self, name: str, attributes: Attributes | None = None) -> None:
        attrs = self._decorate_event_attrs(attributes)

        try:
            self._span.add_event(name, attributes=attrs)
        except Exception:
            pass

        self._console.span_event(
            name=name,
            attributes=attrs,
            trace_id=self._trace_id_hex,
            span_id=self._span_id_hex,
        )

    def record_exception(self, exc: BaseException) -> None:
        try:
            self._span.record_exception(exc)
        except Exception:
            return None

    def set_status_ok(self) -> None:
        self._status = "OK"
        try:
            self._span.set_status(Status(StatusCode.OK))
        except Exception:
            return None

    def set_status_error(self, message: str | None = None) -> None:
        self._status = "ERROR"
        try:
            self._span.set_status(Status(StatusCode.ERROR, description=message))
        except Exception:
            return None

    def is_recording(self) -> bool:
        try:
            return bool(self._span.is_recording())
        except Exception:
            return False


class OtelTracer(TracerPort):
    def __init__(
        self,
        tracer: Any,
        *,
        schema_version: str,
        console: ConsoleRenderer,
    ) -> None:
        self._tracer = tracer
        self._schema_version = schema_version
        self._console = console

    def _decorate_span_attrs(self, attributes: Attributes | None) -> dict[str, Any]:
        attrs: dict[str, Any] = dict(attributes or {})
        attrs.setdefault(semconv.TYCHERION_SCHEMA_VERSION, self._schema_version)
        return attrs

    @contextmanager
    def start_as_current_span(self, name: str, attributes: Attributes | None = None):
        attrs = self._decorate_span_attrs(attributes)

        start_ns = time.time_ns()
        with self._tracer.start_as_current_span(name, attributes=attrs) as span:
            trace_id_hex = _hex_trace_id(span) or ""
            span_id_hex = _hex_span_id(span) or ""

            wrapped = OtelSpan(
                span,
                schema_version=self._schema_version,
                console=self._console,
            )
            self._console.span_started(
                name=name,
                attributes=attrs,
                trace_id=trace_id_hex,
                span_id=span_id_hex,
            )
            try:
                yield wrapped
            finally:
                end_ns = time.time_ns()
                duration_ms = (end_ns - start_ns) / 1_000_000
                error = wrapped.status == "ERROR"
                self._console.span_ended(
                    name=name,
                    status=wrapped.status,
                    duration_ms=duration_ms,
                    trace_id=trace_id_hex,
                    span_id=span_id_hex,
                    error=error,
                )


class OtelTracerProvider(TracerProviderPort):
    def __init__(
        self,
        provider: Any,
        *,
        schema_version: str,
        console: ConsoleRenderer,
    ) -> None:
        self._provider = provider
        self._schema_version = schema_version
        self._console = console

    def get_tracer(self, name: str, version: str | None = None) -> TracerPort:
        tracer = self._provider.get_tracer(name, version)
        return OtelTracer(
            tracer,
            schema_version=self._schema_version,
            console=self._console,
        )

--- tycherion\adapters\observability\otel\otel_traces.py:END ---

--- tycherion\adapters\observability\otel\__init__.py:START ---

--- tycherion\adapters\observability\otel\__init__.py:END ---

--- tycherion\application\pipeline\config.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from typing import Iterable, List

from tycherion.shared.config import AppConfig, PipelineStageCfg


@dataclass(frozen=True, slots=True)
class PipelineStageConfig:
    """Configuration of a single pipeline stage (application-level, YAML-agnostic)."""

    name: str
    drop_threshold: float | None = None


@dataclass(frozen=True, slots=True)
class PipelineConfig:
    """Internal normalized pipeline configuration.

    This object is the only thing the pipeline execution should consume.
    It is intentionally decoupled from YAML and Pydantic.
    """

    stages: List[PipelineStageConfig]


def build_pipeline_config(cfg: AppConfig) -> PipelineConfig:
    """Build a PipelineConfig from the current AppConfig.

    The AppConfig is created by YAML/adapters, but the rest of the application
    should not read YAML-derived structures directly.
    """
    stages_in: Iterable[PipelineStageCfg] = cfg.application.models.pipeline or []
    stages: list[PipelineStageConfig] = []
    for st in stages_in:
        stages.append(
            PipelineStageConfig(
                name=str(st.name),
                drop_threshold=(float(st.drop_threshold) if st.drop_threshold is not None else None),
            )
        )
    if not stages:
        raise RuntimeError(
            "No model pipeline configured. Please set application.models.pipeline in your YAML."
        )
    return PipelineConfig(stages=stages)

--- tycherion\application\pipeline\config.py:END ---

--- tycherion\application\pipeline\result.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict

from tycherion.domain.portfolio.entities import SignalsBySymbol
from tycherion.domain.signals.entities import SymbolState

from .config import PipelineConfig


@dataclass(frozen=True, slots=True)
class PipelineRunResult:
    pipeline_config: PipelineConfig
    states_by_symbol: Dict[str, SymbolState]
    signals_by_symbol: SignalsBySymbol
    stage_stats: Dict[str, int]

--- tycherion\application\pipeline\result.py:END ---

--- tycherion\application\pipeline\service.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from typing import Callable, Dict, Mapping, Optional, Tuple

import pandas as pd

from tycherion.domain.portfolio.entities import PortfolioSnapshot, Signal, SignalsBySymbol
from tycherion.domain.signals.entities import (
    IndicatorOutput,
    ModelDecision,
    ModelStageResult,
    SymbolState,
)
from tycherion.domain.signals.models.base import SignalModel
from tycherion.domain.signals.indicators.base import BaseIndicator
from tycherion.ports.market_data import MarketDataPort

from tycherion.ports.observability import semconv
from tycherion.ports.observability.observability import ObservabilityPort
from tycherion.ports.observability.traces import SpanPort
from tycherion.ports.observability.logs import LoggerPort
from tycherion.ports.observability.types import Severity, TYCHERION_SCHEMA_VERSION

from .config import PipelineConfig, PipelineStageConfig
from .result import PipelineRunResult


@dataclass(slots=True)
class ModelPipelineService:
    """Façade that runs the ordered per-symbol model pipeline."""

    market_data: MarketDataPort
    model_registry: Mapping[str, SignalModel]
    indicator_picker: Callable[[str, Optional[str]], BaseIndicator]
    timeframe: str
    lookback_days: int
    playbook: str | None = None

    def run(
        self,
        universe_symbols: list[str],
        portfolio_snapshot: PortfolioSnapshot,
        pipeline_config: PipelineConfig,
        *,
        observability: ObservabilityPort,
    ) -> PipelineRunResult:
        tracer = observability.traces.get_tracer("tycherion.pipeline", version=TYCHERION_SCHEMA_VERSION)
        logger = observability.logs.get_logger("tycherion.pipeline", version=TYCHERION_SCHEMA_VERSION)

        held_symbols = set(portfolio_snapshot.positions.keys())

        with tracer.start_as_current_span(
            semconv.SPAN_PIPELINE,
            attributes={
                "symbols_count": int(len(universe_symbols)),
                "stages": [st.name for st in pipeline_config.stages],
                "timeframe": self.timeframe,
                "lookback_days": int(self.lookback_days),
            },
        ) as span:
            # 1) Init per-symbol state
            states: Dict[str, SymbolState] = {
                sym: SymbolState(symbol=sym, is_held=(sym in held_symbols))
                for sym in universe_symbols
            }

            # 2) Resolve models
            resolved = self._resolve_models(pipeline_config)

            # 3) Determine indicator needs once for the whole pipeline
            needed_keys: set[str] = set()
            for _, model in resolved:
                try:
                    needed_keys.update(model.requires() or set())
                except Exception:
                    pass

            # 4) Time window for analysis
            end = datetime.now(timezone.utc)
            start = end - timedelta(days=int(self.lookback_days))

            stage_stats: Dict[str, int] = {st.name: 0 for st in pipeline_config.stages}
            stage_passed: Dict[str, int] = {st.name: 0 for st in pipeline_config.stages}

            for st in pipeline_config.stages:
                attrs = {"stage": st.name}
                if st.drop_threshold is not None:
                    attrs["threshold"] = float(st.drop_threshold)
                span.add_event(
                    semconv.EVT_PIPELINE_STAGE_STARTED,
                    attrs,
                )

            for symbol, state in states.items():
                if not state.alive and not state.is_held:
                    continue

                df = self._safe_get_bars(symbol, start, end, state, span, logger)
                if df is None or df.empty:
                    if not state.is_held:
                        logger.emit(
                            "pipeline.symbol_dropped",
                            Severity.WARN,
                            {
                                semconv.ATTR_CHANNEL: "audit",
                                "symbol": symbol,
                                "reason": "no_market_data",
                            },
                        )
                        state.alive = False
                    continue

                if logger.is_enabled(Severity.DEBUG):
                    try:
                        logger.emit(
                            "market_data.sample",
                            Severity.DEBUG,
                            {
                                semconv.ATTR_CHANNEL: "debug",
                                "symbol": symbol,
                                "rows": int(len(df)),
                                "columns": list(df.columns)[:20],
                                "head": df.head(2).to_dict(orient="list"),
                                "tail": df.tail(2).to_dict(orient="list"),
                            },
                        )
                    except Exception:
                        pass

                bundle = self._compute_indicators(df, needed_keys, state, span, logger)

                # Pipeline execution per stage
                for stage_cfg, model in resolved:
                    if not state.alive and not state.is_held:
                        break

                    stage_passed[stage_cfg.name] = int(stage_passed.get(stage_cfg.name, 0)) + 1
                    score = self._run_stage(symbol, stage_cfg, model, bundle, state, span, logger)

                    # Drop policy
                    if stage_cfg.drop_threshold is not None and score < float(stage_cfg.drop_threshold):
                        if state.is_held:
                            state.notes[f"below_threshold_{stage_cfg.name}"] = 1.0
                            continue
                        state.alive = False
                        state.notes[f"dropped_by_{stage_cfg.name}"] = 1.0
                        stage_stats[stage_cfg.name] = int(stage_stats.get(stage_cfg.name, 0)) + 1
                        logger.emit(
                            "pipeline.symbol_dropped",
                            Severity.INFO,
                            {
                                semconv.ATTR_CHANNEL: "audit",
                                "symbol": symbol,
                                "stage": stage_cfg.name,
                                "score": float(score),
                                "threshold": float(stage_cfg.drop_threshold),
                                "reason": "below_threshold",
                            },
                        )
                        break

                # Final signal fields (simple v1 rule: last stage score)
                last_score = float(state.pipeline_results[-1].score) if state.pipeline_results else 0.0
                state.alpha_score = last_score
                state.notes["final_confidence"] = abs(last_score)

            # 5) Convert states into SignalsBySymbol
            signals: SignalsBySymbol = {}
            for symbol, state in states.items():
                if not state.alive and not state.is_held:
                    continue
                signed = float(state.alpha_score)
                confidence = float(state.notes.get("final_confidence", abs(signed)))
                signals[symbol] = Signal(symbol=symbol, signed=signed, confidence=confidence)
                logger.emit(
                    "pipeline.signal_emitted",
                    Severity.INFO,
                    {
                        semconv.ATTR_CHANNEL: "audit",
                        "symbol": symbol,
                        "signed": signed,
                        "confidence": confidence,
                    },
                )

            for st in pipeline_config.stages:
                dropped = int(stage_stats.get(st.name, 0))
                passed = int(stage_passed.get(st.name, 0))
                span.add_event(
                    semconv.EVT_PIPELINE_STAGE_COMPLETED,
                    {
                        "stage": st.name,
                        "passed_count": passed,
                        "dropped_count": dropped,
                        **(
                            {"threshold": float(st.drop_threshold)}
                            if st.drop_threshold is not None
                            else {}
                        ),
                    },
                )

            span.add_event(
                semconv.EVT_PIPELINE_SUMMARY,
                {
                    "signals_count": int(len(signals)),
                    "alive_count": int(sum(1 for s in states.values() if s.alive or s.is_held)),
                },
            )

            return PipelineRunResult(
                pipeline_config=pipeline_config,
                states_by_symbol=states,
                signals_by_symbol=signals,
                stage_stats=stage_stats,
            )

    def _resolve_models(self, pipeline_config: PipelineConfig) -> list[Tuple[PipelineStageConfig, SignalModel]]:
        pipeline: list[Tuple[PipelineStageConfig, SignalModel]] = []
        for stage in pipeline_config.stages:
            name = stage.name
            model = self.model_registry.get(name)
            if model is None:
                available = ", ".join(sorted(self.model_registry.keys()))
                raise RuntimeError(f"Model not found: {name!r}. Available models: {available}")
            pipeline.append((stage, model))
        return pipeline

    def _safe_get_bars(
        self,
        symbol: str,
        start: datetime,
        end: datetime,
        state: SymbolState,
        span: SpanPort,
        logger: LoggerPort,
    ) -> pd.DataFrame | None:
        try:
            return self.market_data.get_bars(symbol, self.timeframe, start, end)
        except Exception as e:
            state.notes["data_error"] = 1.0
            span.record_exception(e)
            logger.emit(
                "error.exception",
                Severity.ERROR,
                {
                    semconv.ATTR_CHANNEL: "ops",
                    "symbol": symbol,
                    "exception_type": type(e).__name__,
                    "message": str(e),
                    "stage": "get_bars",
                },
            )
            return None

    def _compute_indicators(
        self,
        df: pd.DataFrame,
        needed_keys: set[str],
        state: SymbolState,
        span: SpanPort,
        logger: LoggerPort,
    ) -> Dict[str, IndicatorOutput]:
        bundle: Dict[str, IndicatorOutput] = {}
        for key in needed_keys:
            try:
                ind = self.indicator_picker(key, self.playbook)
                bundle[key] = ind.compute(df.copy())
            except Exception as e:
                state.notes[f"indicator_error_{key}"] = 1.0
                span.record_exception(e)
                logger.emit(
                    "error.exception",
                    Severity.ERROR,
                    {
                        semconv.ATTR_CHANNEL: "ops",
                        "exception_type": type(e).__name__,
                        "message": str(e),
                        "stage": "indicator",
                        "indicator": key,
                    },
                )
                bundle[key] = IndicatorOutput(score=0.0, features={})
        return bundle

    def _run_stage(
        self,
        symbol: str,
        stage_cfg: PipelineStageConfig,
        model: SignalModel,
        indicators: Dict[str, IndicatorOutput],
        state: SymbolState,
        span: SpanPort,
        logger: LoggerPort,
    ) -> float:
        stage_name = stage_cfg.name
        try:
            if logger.is_enabled(Severity.DEBUG):
                try:
                    logger.emit(
                        "model.input_snapshot",
                        Severity.DEBUG,
                        {
                            semconv.ATTR_CHANNEL: "debug",
                            "symbol": symbol,
                            "stage": stage_name,
                            "model": stage_name,
                            "indicator_keys": list(indicators.keys())[:30],
                            "features_keys": {
                                k: list(v.features.keys())[:20]
                                for k, v in indicators.items()
                                if getattr(v, "features", None)
                            },
                        },
                    )
                except Exception:
                    pass

            decision = model.decide(indicators)
        except Exception as e:
            state.notes[f"model_error_{stage_name}"] = 1.0
            span.record_exception(e)
            logger.emit(
                "error.exception",
                Severity.ERROR,
                {
                    semconv.ATTR_CHANNEL: "ops",
                    "symbol": symbol,
                    "stage": stage_name,
                    "model": stage_name,
                    "exception_type": type(e).__name__,
                    "message": str(e),
                    "stage_kind": "model",
                },
            )
            decision = ModelDecision(side="HOLD", weight=0.0, confidence=0.0)

        score = self._decision_to_score(decision)
        state.pipeline_results.append(ModelStageResult(model_name=stage_name, score=score))

        logger.emit(
            "model.decided",
            Severity.INFO,
            {
                semconv.ATTR_CHANNEL: "audit",
                "symbol": symbol,
                "stage": stage_name,
                "model": stage_name,
                "score": float(score),
                "side": decision.side,
                "weight": float(decision.weight or 0.0),
                "confidence": float(decision.confidence or 0.0),
            },
        )
        return score

    @staticmethod
    def _decision_to_score(d: ModelDecision) -> float:
        """Map a ModelDecision into a numeric score in [-1, 1]."""
        side = (d.side or "HOLD").upper()
        w = float(d.weight or 0.0)
        w = max(0.0, min(1.0, w))
        if side == "BUY":
            s = w
        elif side == "SELL":
            s = -w
        else:
            s = 0.0
        return max(-1.0, min(1.0, s))

--- tycherion\application\pipeline\service.py:END ---

--- tycherion\application\pipeline\__init__.py:START ---

--- tycherion\application\pipeline\__init__.py:END ---

--- tycherion\application\plugins\registry.py:START ---
from __future__ import annotations

from typing import Dict, List, Iterable

from tycherion.ports.observability.observability import ObservabilityPort
from tycherion.ports.observability.types import Severity, TYCHERION_SCHEMA_VERSION

from tycherion.domain.signals.indicators.base import BaseIndicator
from tycherion.domain.signals.models.base import SignalModel
from tycherion.domain.portfolio.allocators.base import BaseAllocator
from tycherion.domain.portfolio.balancers.base import BaseBalancer

INDICATORS: Dict[str, List[BaseIndicator]] = {}
MODELS: Dict[str, SignalModel] = {}
ALLOCATORS: Dict[str, BaseAllocator] = {}
BALANCERS: Dict[str, BaseBalancer] = {}
DEFAULT_METHOD: Dict[str, str] = {}


def register_indicator(*, key: str, method: str, tags: set[str]):
    """Register an indicator implementation for a given logical key (e.g. "trend")
    and method (e.g. "donchian_50_50").
    """

    def deco(cls):
        inst = cls()
        inst.key = key
        inst.method = method
        inst.tags = tags
        INDICATORS.setdefault(key, []).append(inst)
        return cls

    return deco


def register_model(*, name: str, tags: set[str]):
    """Register a per-symbol signal model."""

    def deco(cls):
        inst = cls()
        inst.name = name
        inst.tags = tags
        MODELS[name] = inst
        return cls

    return deco


def register_allocator(*, name: str, tags: set[str]):
    """Register a portfolio allocator strategy."""

    def deco(cls):
        inst = cls()
        inst.name = name
        inst.tags = tags
        ALLOCATORS[name] = inst
        return cls

    return deco


def register_balancer(*, name: str, tags: set[str]):
    """Register a portfolio balancer / rebalancer strategy."""

    def deco(cls):
        inst = cls()
        inst.name = name
        inst.tags = tags
        BALANCERS[name] = inst
        return cls

    return deco


def set_default_indicator_method(key: str, method: str) -> None:
    DEFAULT_METHOD[key] = method


def pick_indicator_for(key: str, playbook: str | None = None) -> BaseIndicator:
    """Pick an indicator instance for a given key and (optionally) playbook."""

    candidates: Iterable[BaseIndicator] = INDICATORS.get(key, [])
    candidates = list(candidates)
    if not candidates:
        raise KeyError(f"No indicators registered for key={key!r}")

    # filter by tags / playbook
    if playbook:
        tagged = [ind for ind in candidates if playbook in getattr(ind, "tags", set())]
        if tagged:
            candidates = tagged

    # then prefer "default"
    defaults = [ind for ind in candidates if "default" in getattr(ind, "tags", set())]
    if defaults:
        candidates = defaults

    # lastly, prefer DEFAULT_METHOD if configured
    method = DEFAULT_METHOD.get(key)
    if method:
        for ind in candidates:
            if getattr(ind, "method", None) == method:
                return ind

    return candidates[0]


def auto_discover(*, observability: ObservabilityPort | None) -> None:
    """Import all plugin modules so that their decorators run and fill registries."""

    import importlib
    import pkgutil

    tracer = observability.traces.get_tracer("tycherion.plugins", version=TYCHERION_SCHEMA_VERSION) if observability else None
    logger = observability.logs.get_logger("tycherion.plugins", version=TYCHERION_SCHEMA_VERSION) if observability else None

    def _log(body: str, severity: Severity, **data) -> None:
        if logger is None:
            return
        attrs = {"tycherion.channel": "ops", **data}
        logger.emit(body, severity, attrs)

    bases = (
        "tycherion.domain.signals.indicators",
        "tycherion.domain.signals.models",
        "tycherion.domain.portfolio.allocators",
        "tycherion.domain.portfolio.balancers",
    )

    if tracer is None:
        # No observability: best effort discovery without logs.
        for base in bases:
            pkg = importlib.import_module(base)
            for mod in pkgutil.walk_packages(getattr(pkg, "__path__", None), pkg.__name__ + "."):
                importlib.import_module(mod.name)
        return

    with tracer.start_as_current_span("plugins.discover", attributes={"component": "plugins"}):
        for base in bases:
            try:
                pkg = importlib.import_module(base)
            except Exception as e:
                _log("plugins.base_import_failed", Severity.WARN, base=base, error=str(e))
                continue

            pkg_path = getattr(pkg, "__path__", None)
            if not pkg_path:
                continue

            for mod in pkgutil.walk_packages(pkg_path, pkg.__name__ + "."):
                try:
                    importlib.import_module(mod.name)
                except Exception as e:
                    _log("plugins.module_import_failed", Severity.WARN, module=mod.name, error=str(e))

        _log(
            "plugins.discovered",
            Severity.INFO,
            indicators_count=int(sum(len(v) for v in INDICATORS.values())),
            models_count=int(len(MODELS)),
            allocators_count=int(len(ALLOCATORS)),
            balancers_count=int(len(BALANCERS)),
        )

--- tycherion\application\plugins\registry.py:END ---

--- tycherion\application\runmodes\live_multimodel.py:START ---
from __future__ import annotations

import hashlib
import json
import time
from typing import Dict

from tycherion.shared.config import AppConfig
from tycherion.ports.trading import TradingPort
from tycherion.ports.account import AccountPort
from tycherion.ports.universe import UniversePort

from tycherion.ports.observability import semconv
from tycherion.ports.observability.observability import ObservabilityPort
from tycherion.ports.observability.types import Severity, TYCHERION_SCHEMA_VERSION

from tycherion.application.plugins.registry import (
    ALLOCATORS,
    BALANCERS,
)
from tycherion.application.services.coverage_selector import build_coverage
from tycherion.application.services.order_planner import build_orders
from tycherion.domain.portfolio.entities import (
    PortfolioSnapshot,
    Position,
)

from tycherion.application.pipeline.config import build_pipeline_config
from tycherion.application.pipeline.service import ModelPipelineService


def _build_portfolio_snapshot(account: AccountPort) -> PortfolioSnapshot:
    equity = float(account.equity())
    positions: Dict[str, Position] = {}
    for p in account.positions():
        positions[p.symbol] = p
    return PortfolioSnapshot(equity=equity, positions=positions)


def _stable_config_hash(d: dict) -> str:
    try:
        blob = json.dumps(d, sort_keys=True, default=str).encode("utf-8")
        return hashlib.sha256(blob).hexdigest()[:16]
    except Exception:
        return ""


def run_live_multimodel(
    cfg: AppConfig,
    trader: TradingPort,
    account: AccountPort,
    universe: UniversePort,
    pipeline_service: ModelPipelineService,
    *,
    observability: ObservabilityPort,
    config_path: str | None = None,
) -> None:
    """Live runmode that delegates per-symbol pipeline execution to ModelPipelineService."""

    allocator = ALLOCATORS.get(cfg.application.portfolio.allocator)
    if not allocator:
        raise RuntimeError(f"Allocator not found: {cfg.application.portfolio.allocator!r}")

    balancer = BALANCERS.get(cfg.application.portfolio.balancer)
    if not balancer:
        raise RuntimeError(f"Balancer not found: {cfg.application.portfolio.balancer!r}")

    pipeline_config = build_pipeline_config(cfg)

    tracer = observability.traces.get_tracer("tycherion.runmodes.live_multimodel", version=TYCHERION_SCHEMA_VERSION)
    logger = observability.logs.get_logger("tycherion.runmodes.live_multimodel", version=TYCHERION_SCHEMA_VERSION)

    def step_once() -> None:
        cfg_hash = _stable_config_hash(cfg.model_dump())

        with tracer.start_as_current_span(
            semconv.SPAN_RUN,
            attributes={
                semconv.ATTR_RUN_MODE: "live_multimodel",
                "timeframe": cfg.timeframe,
                "lookback_days": int(cfg.lookback_days),
                "pipeline_stages": [st.name for st in pipeline_config.stages],
                semconv.ATTR_CONFIG_HASH: cfg_hash,
                semconv.ATTR_CONFIG_PATH: config_path,
            },
        ) as span_run:
            try:
                # 1) Structural universe from coverage + ensure held symbols are included
                with tracer.start_as_current_span(semconv.SPAN_COVERAGE_FETCH) as span_cov:
                    coverage = build_coverage(cfg, pipeline_service.market_data, universe)
                    portfolio = _build_portfolio_snapshot(account)
                    held_symbols = set(portfolio.positions.keys())
                    universe_symbols = sorted(set(coverage) | held_symbols)

                    span_cov.add_event(
                        semconv.EVT_COVERAGE_SUMMARY,
                        {
                            "symbols_count": int(len(universe_symbols)),
                            "symbols_sample": universe_symbols[: min(10, len(universe_symbols))],
                        },
                    )

                # 2) Run pipeline (single entrypoint)
                result = pipeline_service.run(
                    universe_symbols=universe_symbols,
                    portfolio_snapshot=portfolio,
                    pipeline_config=pipeline_config,
                    observability=observability,
                )

                span_run.add_event(
                    semconv.EVT_PIPELINE_RUN_SUMMARY,
                    {f"stage_stats.{k}": int(v) for k, v in (result.stage_stats or {}).items()},
                )

                # 3) Allocation -> target weights
                with tracer.start_as_current_span(semconv.SPAN_ALLOCATOR) as span_alloc:
                    target_alloc = allocator.allocate(result.signals_by_symbol)
                    span_alloc.add_event(semconv.EVT_ALLOCATOR_COMPLETED, {"symbols_count": int(len(result.signals_by_symbol))})

                # 4) Balancing -> rebalance plan
                with tracer.start_as_current_span(semconv.SPAN_BALANCER) as span_bal:
                    plan = balancer.plan(
                        portfolio=portfolio,
                        target=target_alloc,
                        threshold=cfg.application.portfolio.threshold_weight,
                    )
                    span_bal.add_event(semconv.EVT_REBALANCE_PLAN_BUILT, {"instructions_count": int(len(plan))})

                # 5) Orders -> execution
                with tracer.start_as_current_span(semconv.SPAN_EXECUTION) as span_exec:
                    orders = build_orders(portfolio, plan, cfg.trading)
                    span_exec.add_event(semconv.EVT_ORDERS_BUILT, {"orders_count": int(len(orders))})

                    for od in orders:
                        if od.side.upper() == "BUY":
                            res = trader.market_buy(od.symbol, volume=od.volume)
                        else:
                            res = trader.market_sell(od.symbol, volume=od.volume)

                        logger.emit(
                            "trade.executed",
                            Severity.INFO,
                            {
                                semconv.ATTR_CHANNEL: "ops",
                                "symbol": od.symbol,
                                "side": od.side,
                                "volume": float(od.volume),
                                "result": str(res),
                            },
                        )

                span_run.set_status_ok()
            except BaseException as e:
                span_run.record_exception(e)
                span_run.set_status_error(str(e))
                logger.emit(
                    "run.exception",
                    Severity.ERROR,
                    {
                        semconv.ATTR_CHANNEL: "ops",
                        "run_mode": "live_multimodel",
                        "exception_type": type(e).__name__,
                        "message": str(e),
                    },
                )
                raise

    if cfg.application.schedule.run_forever:
        while True:
            try:
                step_once()
                time.sleep(max(1, cfg.application.schedule.interval_seconds))
            except KeyboardInterrupt:
                logger.emit(
                    "run.stopped",
                    Severity.INFO,
                    {
                        semconv.ATTR_CHANNEL: "ops",
                        "run_mode": "live_multimodel",
                        "reason": "KeyboardInterrupt",
                    },
                )
                break
            except Exception as e:
                # Error already recorded inside the run span, but keep a top-level log too.
                logger.emit(
                    "run.loop_exception",
                    Severity.ERROR,
                    {
                        semconv.ATTR_CHANNEL: "ops",
                        "run_mode": "live_multimodel",
                        "exception_type": type(e).__name__,
                        "message": str(e),
                    },
                )
                time.sleep(3)
    else:
        step_once()

--- tycherion\application\runmodes\live_multimodel.py:END ---

--- tycherion\application\services\coverage_selector.py:START ---
from __future__ import annotations

from tycherion.shared.config import AppConfig
from tycherion.ports.market_data import MarketDataPort
from tycherion.ports.universe import UniversePort


def _build_base_coverage(cfg: AppConfig, universe: UniversePort) -> list[str]:
    """Build the *structural* universe of symbols.

    Coverage is intentionally dumb. It only answers: *which* symbols should be
    considered, based on the configured source. Any kind of "smart filtering"
    (liquidity, regimes, sanity checks, alpha, etc.) must live in the model
    pipeline, not here.
    """
    src = (cfg.application.coverage.source or "").lower()
    if src == "static":
        # Remove duplicates while preserving order
        return list(dict.fromkeys(cfg.application.coverage.symbols or []))
    if src == "market_watch":
        return universe.visible_symbols()
    if src == "pattern":
        patt = cfg.application.coverage.pattern or "*"
        return universe.by_pattern(patt)
    return universe.visible_symbols()


def build_coverage(cfg: AppConfig, data: MarketDataPort, universe: UniversePort) -> list[str]:
    """Build the list of symbols to analyse in this run.

    NOTE: `data` is kept in the signature for backward compatibility, but is
    intentionally unused. The universe thinning that previously depended on
    recent `tick_volume` (coverage.top_n) is deprecated and removed.
    """
    _ = data  # explicit unused
    return _build_base_coverage(cfg, universe)

--- tycherion\application\services\coverage_selector.py:END ---

--- tycherion\application\services\ensemble.py:START ---
# application/services/ensemble.py (versão nova)

from __future__ import annotations

from typing import List
from tycherion.domain.signals.entities import ModelDecision, AggregatedDecision


def combine(decisions: List[ModelDecision]) -> AggregatedDecision:
    """
    Combina uma lista de ModelDecision em uma decisão agregada única.
    """
    if not decisions:
        return AggregatedDecision(
            side="HOLD",
            weight=0.0,
            confidence=0.0,
            signed=0.0,
        )

    num, den = 0.0, 0.0
    for d in decisions:
        side = (d.side or "HOLD").upper()
        w = float(d.weight)
        c = float(d.confidence if d.confidence is not None else 0.5)
        c = max(0.0, min(1.0, c))

        if side == "BUY":
            signed = w
        elif side == "SELL":
            signed = -w
        else:
            signed = 0.0

        num += signed * c
        den += c

    if den <= 0:
        return AggregatedDecision(
            side="HOLD",
            weight=0.0,
            confidence=0.0,
            signed=0.0,
        )

    s = num / den
    side = "BUY" if s > 0.1 else ("SELL" if s < -0.1 else "HOLD")
    weight = min(1.0, abs(s))
    confidence = min(1.0, den / max(1, len(decisions)))

    return AggregatedDecision(
        side=side,
        weight=weight,
        confidence=confidence,
        signed=s,
    )


--- tycherion\application\services\ensemble.py:END ---

--- tycherion\application\services\order_planner.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from typing import List

from tycherion.domain.portfolio.entities import PortfolioSnapshot, RebalanceInstruction
from tycherion.shared.config import Trading


@dataclass
class SuggestedOrder:
    symbol: str
    side: str   # "BUY" | "SELL"
    volume: float


def build_orders(
    portfolio: PortfolioSnapshot,
    plan: List[RebalanceInstruction],
    trading_cfg: Trading,
) -> List[SuggestedOrder]:
    """
    Convert domain-level rebalance instructions (expressed in weights) into
    concrete order suggestions with broker volumes. This is the point where
    we cross from the pure portfolio domain into broker-specific constraints.
    """
    # Lazy import to avoid circular deps
    from tycherion.application.services.sizer import (
        volume_from_weight,
        symbol_min_volume,
    )

    orders: List[SuggestedOrder] = []
    for instr in plan:
        # For now we scale volumes solely by absolute delta_weight. In the
        # future this can incorporate volatility, risk, etc.
        w = abs(float(instr.delta_weight))
        if w <= 0.0:
            continue

        vol = volume_from_weight(
            instr.symbol,
            w,
            trading_cfg.volume_mode,
            trading_cfg.fixed_volume,
        )
        min_vol = symbol_min_volume(instr.symbol)
        vol = max(vol, min_vol)
        if vol <= 0.0:
            continue

        orders.append(
            SuggestedOrder(
                symbol=instr.symbol,
                side=instr.side,
                volume=vol,
            )
        )
    return orders


--- tycherion\application\services\order_planner.py:END ---

--- tycherion\application\services\sizer.py:START ---
from __future__ import annotations
import MetaTrader5 as mt5

def symbol_min_volume(symbol: str) -> float:
    info = mt5.symbol_info(symbol)
    if not info:
        return 0.0
    v = max(info.volume_min, info.volume_step)
    steps = round(v / info.volume_step)
    return steps * info.volume_step

def volume_from_weight(symbol: str, weight: float, mode: str, fixed_volume: float) -> float:
    weight = max(0.0, min(1.0, float(weight)))
    if weight < 1e-6:
        return 0.0
    if mode == 'fixed':
        return float(fixed_volume) * weight
    return symbol_min_volume(symbol)


--- tycherion\application\services\sizer.py:END ---

--- tycherion\bootstrap\main.py:START ---
from __future__ import annotations

import os
import socket
import uuid

import MetaTrader5 as mt5

from tycherion.shared.config import load_config, AppConfig
from tycherion.adapters.mt5.market_data_mt5 import MT5MarketData
from tycherion.adapters.mt5.trading_mt5 import MT5Trader
from tycherion.adapters.mt5.account_mt5 import MT5Account
from tycherion.adapters.mt5.universe_mt5 import MT5Universe

from tycherion.adapters.observability.noop.noop_observability import NoopObservability

from tycherion.ports.observability import semconv
from tycherion.ports.observability.observability import ObservabilityPort
from tycherion.ports.observability.types import Severity, TYCHERION_SCHEMA_VERSION

from tycherion.application.plugins import registry as _registry
from tycherion.application.pipeline.service import ModelPipelineService
from tycherion.application.runmodes.live_multimodel import run_live_multimodel


def _ensure_initialized(cfg: AppConfig) -> None:
    if not mt5.initialize(path=cfg.mt5.terminal_path or None):
        raise SystemExit(f"MT5 initialize failed: {mt5.last_error()}")
    if cfg.mt5.login and cfg.mt5.password and cfg.mt5.server:
        if not mt5.login(
            login=int(cfg.mt5.login),
            password=cfg.mt5.password,
            server=cfg.mt5.server,
        ):
            raise SystemExit(f"MT5 login failed: {mt5.last_error()}")


def run_app(config_path: str) -> None:
    cfg = load_config(config_path)

    # Observability must be available as early as possible (e.g. plugin discovery).
    obs = _build_observability(cfg, config_path)

    tracer = obs.traces.get_tracer("tycherion.bootstrap", version=TYCHERION_SCHEMA_VERSION)
    logger = obs.logs.get_logger("tycherion.bootstrap", version=TYCHERION_SCHEMA_VERSION)

    with tracer.start_as_current_span(semconv.SPAN_BOOTSTRAP_DISCOVER, attributes={"component": "bootstrap"}):
        _registry.auto_discover(observability=obs)
        logger.emit("Plugin discovery completed", Severity.INFO, {semconv.ATTR_CHANNEL: "ops"})

    _ensure_initialized(cfg)
    try:
        market_data = MT5MarketData()
        trader = MT5Trader(
            dry_run=cfg.trading.dry_run,
            require_demo=cfg.trading.require_demo,
            deviation_points=cfg.trading.deviation_points,
            volume_mode=cfg.trading.volume_mode,
            fixed_volume=cfg.trading.fixed_volume,
        )
        account = MT5Account()
        universe = MT5Universe()

        pipeline_service = ModelPipelineService(
            market_data=market_data,
            model_registry=_registry.MODELS,
            indicator_picker=_registry.pick_indicator_for,
            timeframe=cfg.timeframe,
            lookback_days=cfg.lookback_days,
            playbook=cfg.application.playbook,
        )

        run_mode = (cfg.application.run_mode.name or "").lower()
        if run_mode == "live_multimodel":
            run_live_multimodel(
                cfg,
                trader,
                account,
                universe,
                pipeline_service,
                observability=obs,
                config_path=config_path,
            )
        else:
            raise SystemExit(f"Unknown run_mode: {run_mode}")
    finally:
        try:
            obs.shutdown()
        except Exception:
            pass
        mt5.shutdown()


def _parse_severity(level: str | None) -> Severity:
    lvl = (level or "INFO").strip().upper()
    try:
        return Severity[lvl]
    except Exception:
        # Accept legacy values too
        if lvl in ("WARNING",):
            return Severity.WARN
        return Severity.INFO


def _build_observability(cfg: AppConfig, config_path: str) -> ObservabilityPort:
    _ = config_path

    runner_id = (os.getenv("TYCHERION_RUNNER_ID") or "").strip()
    if not runner_id:
        # Fallback: deterministic enough for local dev.
        runner_id = f"runner-{socket.gethostname()}-{os.getpid()}"
    run_id = uuid.uuid4().hex

    tel = cfg.observability or cfg.telemetry  # telemetry kept for backward compat
    deployment_env = (tel.deployment_env or "").strip() or None

    try:
        from tycherion.adapters.observability.otel.otel_observability import (
            OtelObservability,
            OtelObservabilityConfig,
        )

        return OtelObservability(
            OtelObservabilityConfig(
                runner_id=runner_id,
                run_id=run_id,
                schema_version=TYCHERION_SCHEMA_VERSION,
                deployment_env=deployment_env,
                console_enabled=bool(tel.console_enabled),
                console_min_severity=_parse_severity(tel.console_min_level),
                console_show_span_lifecycle=True,
                log_format=str(getattr(tel, "log_format", "pretty") or "pretty"),
                otlp_enabled=bool(getattr(tel, "otlp_enabled", False)),
                otlp_endpoint=str(getattr(tel, "otlp_endpoint", "http://localhost:4317") or "http://localhost:4317"),
                otlp_protocol=str(getattr(tel, "otlp_protocol", "grpc") or "grpc"),
                otlp_headers=getattr(tel, "otlp_headers", None),
                otlp_insecure=getattr(tel, "otlp_insecure", None),
            )
        )
    except Exception as e:
        # Hard-fail would be annoying during local dev if deps are missing, so we degrade to noop.
        print(f"[tycherion] Observability disabled (failed to init OTel adapter): {e}")
        return NoopObservability()

--- tycherion\bootstrap\main.py:END ---

--- tycherion\domain\__init__.py:START ---

--- tycherion\domain\__init__.py:END ---

--- tycherion\domain\market\entities.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import NewType

Symbol = NewType("Symbol", str)


class AssetClass(str, Enum):
    EQUITY = "equity"
    FUTURE = "future"
    FX = "fx"
    OTHER = "other"


@dataclass
class Instrument:
    """Domain representation of a tradable instrument (stock, future, FX, etc.)."""

    symbol: Symbol
    asset_class: AssetClass
    currency: str
    lot_size: float
    min_volume: float
    volume_step: float


@dataclass
class Bar:
    """Minimal OHLCV bar used by indicators and models when not using DataFrame."""

    symbol: Symbol
    time: datetime
    open: float
    high: float
    low: float
    close: float
    volume: float

--- tycherion\domain\market\entities.py:END ---

--- tycherion\domain\market\__init__.py:START ---

--- tycherion\domain\market\__init__.py:END ---

--- tycherion\domain\portfolio\entities.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict


Symbol = str


@dataclass
class Signal:
    """Per-symbol signal produced by the models/ensemble.

    signed: desired direction/intensity in [-1, 1]
    confidence: optional confidence level in [0, 1]
    """

    symbol: Symbol
    signed: float
    confidence: float = 1.0


SignalsBySymbol = Dict[Symbol, Signal]


@dataclass
class Position:
    """Domain-level position in a single instrument.

    quantity: number of shares/contracts/etc.
    price: best available price estimate (e.g. last close or avg price).
    """

    symbol: Symbol
    quantity: float
    price: float


@dataclass
class PortfolioSnapshot:
    """Portfolio snapshot used by allocators/balancers at the domain level.

    Equity is the current account equity in account currency.
    """

    equity: float
    positions: Dict[Symbol, Position]

    def weight_of(self, symbol: Symbol) -> float:
        pos = self.positions.get(symbol)
        if not pos or self.equity <= 0:
            return 0.0
        return float(pos.quantity * pos.price) / float(self.equity)


@dataclass
class TargetAllocation:
    """Target portfolio allocation expressed as weights per symbol in [-1, 1].

    Positive weights are long exposure, negative weights are short exposure.
    """

    weights: Dict[Symbol, float]


@dataclass
class RebalanceInstruction:
    """Domain-level rebalance instruction expressed in weights, not broker
    volumes. Conversion to concrete order sizes happens in the application
    layer (order planner).
    """

    symbol: Symbol
    from_weight: float
    to_weight: float
    delta_weight: float
    side: str  # "BUY" | "SELL"

--- tycherion\domain\portfolio\entities.py:END ---

--- tycherion\domain\portfolio\__init__.py:START ---

--- tycherion\domain\portfolio\__init__.py:END ---

--- tycherion\domain\portfolio\allocators\base.py:START ---
from __future__ import annotations

from abc import ABC, abstractmethod

from tycherion.domain.portfolio.entities import SignalsBySymbol, TargetAllocation


class BaseAllocator(ABC):
    """Abstract base class for portfolio allocator plugins."""

    # Set by decorator
    name: str = ""
    tags: set[str] = set()

    @abstractmethod
    def allocate(self, signals: SignalsBySymbol) -> TargetAllocation:
        raise NotImplementedError

--- tycherion\domain\portfolio\allocators\base.py:END ---

--- tycherion\domain\portfolio\allocators\equal_weight.py:START ---
from __future__ import annotations

from tycherion.domain.portfolio.allocators.base import BaseAllocator
from tycherion.application.plugins.registry import register_allocator
from tycherion.domain.portfolio.entities import SignalsBySymbol, TargetAllocation


@register_allocator(name="equal_weight", tags={"default"})
class EqualWeightAllocator(BaseAllocator):
    """
    Simple allocator: gives the same absolute weight to all symbols that have
    a non-zero signal. Longs get +w, shorts get -w, holds get 0.
    """
    def allocate(self, signals: SignalsBySymbol) -> TargetAllocation:
        nonzero = [s for s in signals.values() if abs(float(s.signed)) > 1e-6]
        if not nonzero:
            # nothing to do
            return TargetAllocation(weights={})

        w = 1.0 / float(len(nonzero))
        weights: dict[str, float] = {}
        for sig in signals.values():
            if sig.signed > 0:
                weights[sig.symbol] = w
            elif sig.signed < 0:
                weights[sig.symbol] = -w
            else:
                weights[sig.symbol] = 0.0
        return TargetAllocation(weights=weights)

--- tycherion\domain\portfolio\allocators\equal_weight.py:END ---

--- tycherion\domain\portfolio\allocators\proportional.py:START ---
from __future__ import annotations

from tycherion.domain.portfolio.allocators.base import BaseAllocator
from tycherion.application.plugins.registry import register_allocator
from tycherion.domain.portfolio.entities import SignalsBySymbol, TargetAllocation


@register_allocator(name="proportional", tags={"default"})
class ProportionalAllocator(BaseAllocator):
    """
    Allocator that gives each symbol a weight proportional to the absolute
    value of its signal. Signals are normalised so that the sum of absolute
    weights is 1. Longs get +w, shorts get -w.
    """
    def allocate(self, signals: SignalsBySymbol) -> TargetAllocation:
        total = sum(abs(float(s.signed)) for s in signals.values())
        if total <= 1e-9:
            return TargetAllocation(weights={})

        weights: dict[str, float] = {}
        for sig in signals.values():
            if sig.signed == 0:
                weights[sig.symbol] = 0.0
            else:
                frac = abs(float(sig.signed)) / total
                weights[sig.symbol] = frac if sig.signed > 0 else -frac
        return TargetAllocation(weights=weights)

--- tycherion\domain\portfolio\allocators\proportional.py:END ---

--- tycherion\domain\portfolio\allocators\__init__.py:START ---

--- tycherion\domain\portfolio\allocators\__init__.py:END ---

--- tycherion\domain\portfolio\balancers\base.py:START ---
from __future__ import annotations

from abc import ABC, abstractmethod

from tycherion.domain.portfolio.entities import (
    PortfolioSnapshot,
    TargetAllocation,
    RebalanceInstruction,
)


class BaseBalancer(ABC):
    """Abstract base class for portfolio balancer / rebalancer plugins."""

    # Set by decorator
    name: str = ""
    tags: set[str] = set()

    @abstractmethod
    def plan(
        self,
        portfolio: PortfolioSnapshot,
        target: TargetAllocation,
        threshold: float = 0.25,
    ) -> list[RebalanceInstruction]:
        raise NotImplementedError

--- tycherion\domain\portfolio\balancers\base.py:END ---

--- tycherion\domain\portfolio\balancers\threshold.py:START ---
from __future__ import annotations

from tycherion.domain.portfolio.balancers.base import BaseBalancer
from tycherion.application.plugins.registry import register_balancer
from tycherion.domain.portfolio.entities import (
    PortfolioSnapshot,
    TargetAllocation,
    RebalanceInstruction,
)


@register_balancer(name="threshold", tags={"default"})
class ThresholdBalancer(BaseBalancer):
    """
    Domain-level balancer: generates rebalance instructions whenever the
    difference between current and target weight is greater than or equal
    to a configured threshold.
    """
    def plan(
        self,
        portfolio: PortfolioSnapshot,
        target: TargetAllocation,
        threshold: float = 0.25,
    ) -> list[RebalanceInstruction]:
        threshold = max(0.0, min(1.0, float(threshold)))
        instructions: list[RebalanceInstruction] = []

        symbols = set(target.weights.keys()) | set(portfolio.positions.keys())
        for sym in sorted(symbols):
            current_w = float(portfolio.weight_of(sym))
            target_w = float(target.weights.get(sym, 0.0))
            delta = target_w - current_w
            if abs(delta) < threshold:
                continue
            side = "BUY" if delta > 0 else "SELL"
            instructions.append(
                RebalanceInstruction(
                    symbol=sym,
                    from_weight=current_w,
                    to_weight=target_w,
                    delta_weight=delta,
                    side=side,
                )
            )
        return instructions

--- tycherion\domain\portfolio\balancers\threshold.py:END ---

--- tycherion\domain\portfolio\balancers\__init__.py:START ---

--- tycherion\domain\portfolio\balancers\__init__.py:END ---

--- tycherion\domain\signals\entities.py:START ---
from __future__ import annotations

from dataclasses import dataclass, field
from typing import Dict, List


@dataclass
class IndicatorOutput:
    """Standard output of an indicator for a single symbol.

    - score: aggregated metric in [-1, 1] (by convention in this project)
    - features: extra numeric features that models may consume.
    """

    score: float
    features: Dict[str, float]


@dataclass
class ModelDecision:
    """Per-model decision for a single symbol.

    side: "BUY" | "SELL" | "HOLD"
    weight: relative intensity (usually in [0, 1])
    confidence: confidence level in [0, 1]
    """

    side: str
    weight: float
    confidence: float

@dataclass
class AggregatedDecision:
    """
    Decisão agregada (ensemble) de todos os models para um símbolo.

    side       -> direção final ("BUY"/"SELL"/"HOLD")
    weight     -> intensidade em [0, 1]
    confidence -> confiança em [0, 1]
    signed     -> direção * intensidade em [-1, 1]
    """
    side: str
    weight: float
    confidence: float
    signed: float


@dataclass
class ModelStageResult:
    """Result for a symbol at a specific model stage in the pipeline."""

    model_name: str
    score: float


@dataclass
class SymbolState:
    """Mutable per-symbol state that flows through the analysis pipeline.

    This is intentionally generic so we can reuse it for universe filters,
    macro models and per-symbol alpha models over time.
    """
    symbol: str
    is_held: bool = False      # True if the symbol is currently in the portfolio
    alive: bool = True         # If False and not held, the symbol can be dropped from the pipeline

    base_score: float = 0.0    # Optional starting score (e.g. from simple filters)
    sanity_score: float = 0.0  # Data-quality / tradability / liquidity score
    macro_score: float = 0.0   # Macro / regime score for this symbol
    alpha_score: float = 0.0   # Final alpha-like score, typically coming from signal models

    pipeline_results: List[ModelStageResult] = field(default_factory=list)

    notes: Dict[str, float] = field(default_factory=dict)


--- tycherion\domain\signals\entities.py:END ---

--- tycherion\domain\signals\__init__.py:START ---

--- tycherion\domain\signals\__init__.py:END ---

--- tycherion\domain\signals\indicators\base.py:START ---
from __future__ import annotations

from abc import ABC, abstractmethod
import pandas as pd

from tycherion.domain.signals.entities import IndicatorOutput


class BaseIndicator(ABC):
    """Abstract base class for indicator plugins."""

    # Set by decorator
    key: str = ""
    method: str = ""
    tags: set[str] = set()

    @abstractmethod
    def compute(self, df: pd.DataFrame) -> IndicatorOutput:
        raise NotImplementedError

--- tycherion\domain\signals\indicators\base.py:END ---

--- tycherion\domain\signals\indicators\stretch_zscore.py:START ---
from __future__ import annotations

from tycherion.domain.signals.indicators.base import BaseIndicator
import pandas as pd

from tycherion.application.plugins.registry import register_indicator
from tycherion.domain.signals.entities import IndicatorOutput


@register_indicator(key="stretch", method="zscore_20", tags={"default"})
class StretchZScore20(BaseIndicator):
    period = 20

    def compute(self, df: pd.DataFrame) -> IndicatorOutput:
        if df.empty or len(df) < self.period:
            return IndicatorOutput(score=0.0, features={})
        close = df["close"].astype(float)
        ma = close.rolling(self.period).mean()
        sd = close.rolling(self.period).std(ddof=0).replace(0, 1e-9)
        z = (close - ma) / sd
        zval = float(z.iloc[-1])
        score = max(-1.0, min(1.0, -zval / 3.0))
        return IndicatorOutput(score=score, features={"z": zval})

--- tycherion\domain\signals\indicators\stretch_zscore.py:END ---

--- tycherion\domain\signals\indicators\trend_donchian.py:START ---
from __future__ import annotations

from tycherion.domain.signals.indicators.base import BaseIndicator
import pandas as pd

from tycherion.application.plugins.registry import register_indicator
from tycherion.domain.signals.entities import IndicatorOutput


@register_indicator(key="trend", method="donchian_50_50", tags={"default"})
class TrendDonchian5050(BaseIndicator):
    high_n = 50
    low_n = 50

    def compute(self, df: pd.DataFrame) -> IndicatorOutput:
        if df.empty or len(df) < max(self.high_n, self.low_n):
            return IndicatorOutput(score=0.0, features={})
        hh = df["high"].rolling(self.high_n).max()
        ll = df["low"].rolling(self.low_n).min()
        mid = (hh + ll) / 2.0
        rng = (hh - ll).replace(0, 1e-9)
        pos = (df["close"] - mid) / (rng / 2.0)
        score = float(pos.iloc[-1])
        score = max(-1.0, min(1.0, score))
        return IndicatorOutput(
            score=score,
            features={"upper": float(hh.iloc[-1]), "lower": float(ll.iloc[-1])},
        )

--- tycherion\domain\signals\indicators\trend_donchian.py:END ---

--- tycherion\domain\signals\indicators\volatility_atr.py:START ---
from __future__ import annotations

from tycherion.domain.signals.indicators.base import BaseIndicator
import pandas as pd

from tycherion.application.plugins.registry import register_indicator
from tycherion.domain.signals.entities import IndicatorOutput


@register_indicator(key="volatility", method="atr_14", tags={"default"})
class VolATR14(BaseIndicator):
    period = 14

    def compute(self, df: pd.DataFrame) -> IndicatorOutput:
        if df.empty or len(df) < self.period + 1:
            return IndicatorOutput(score=0.0, features={})
        high = df["high"].astype(float)
        low = df["low"].astype(float)
        close = df["close"].astype(float)
        prev_close = close.shift(1)
        tr = (high - low).abs()
        tr = pd.concat(
            [tr, (high - prev_close).abs(), (low - prev_close).abs()], axis=1
        ).max(axis=1)
        atr = tr.rolling(self.period).mean()
        val = float(atr.iloc[-1])
        score = 1.0 / (1.0 + val) if val > 0 else 0.0
        return IndicatorOutput(score=score, features={"atr": val})

--- tycherion\domain\signals\indicators\volatility_atr.py:END ---

--- tycherion\domain\signals\indicators\__init__.py:START ---

--- tycherion\domain\signals\indicators\__init__.py:END ---

--- tycherion\domain\signals\models\base.py:START ---
from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Dict

from tycherion.domain.signals.entities import IndicatorOutput, ModelDecision


class SignalModel(ABC):
    """Abstract base class for per-symbol signal models."""

    name: str = ""
    tags: set[str] = set()

    @abstractmethod
    def requires(self) -> set[str]:
        raise NotImplementedError

    @abstractmethod
    def decide(self, indicators: Dict[str, IndicatorOutput]) -> ModelDecision:
        raise NotImplementedError

--- tycherion\domain\signals\models\base.py:END ---

--- tycherion\domain\signals\models\mean_reversion.py:START ---
from __future__ import annotations

from tycherion.domain.signals.models.base import SignalModel
from typing import Dict

from tycherion.application.plugins.registry import register_model
from tycherion.domain.signals.entities import IndicatorOutput, ModelDecision


@register_model(name="mean_reversion", tags={"default"})
class MeanReversion(SignalModel):
    def requires(self) -> set[str]:
        return {"stretch", "volatility"}

    def decide(self, indicators: Dict[str, IndicatorOutput]) -> ModelDecision:
        stretch = indicators.get("stretch") if indicators is not None else None
        z = float(stretch.features.get("z", 0.0)) if stretch else 0.0

        if z <= -2.0:
            w = min(1.0, abs(z) / 3.0)
            return ModelDecision(side="BUY", weight=w, confidence=0.6)
        if z >= 2.0:
            w = min(1.0, abs(z) / 3.0)
            return ModelDecision(side="SELL", weight=w, confidence=0.6)
        return ModelDecision(side="HOLD", weight=0.0, confidence=0.4)


--- tycherion\domain\signals\models\mean_reversion.py:END ---

--- tycherion\domain\signals\models\trend_following.py:START ---
from __future__ import annotations

from tycherion.domain.signals.models.base import SignalModel
from typing import Dict

from tycherion.application.plugins.registry import register_model
from tycherion.domain.signals.entities import IndicatorOutput, ModelDecision


@register_model(name="trend_following", tags={"default"})
class TrendFollowing(SignalModel):
    def requires(self) -> set[str]:
        return {"trend", "volatility"}

    def decide(self, indicators: Dict[str, IndicatorOutput]) -> ModelDecision:
        trend = indicators.get("trend") if indicators is not None else None
        tr = float(trend.score) if trend else 0.0

        if tr > 0.2:
            return ModelDecision(
                side="BUY",
                weight=min(1.0, 0.5 + tr * 0.5),
                confidence=0.7,
            )
        if tr < -0.2:
            return ModelDecision(
                side="SELL",
                weight=min(1.0, 0.5 + (-tr) * 0.5),
                confidence=0.7,
            )
        return ModelDecision(side="HOLD", weight=0.0, confidence=0.3)


--- tycherion\domain\signals\models\trend_following.py:END ---

--- tycherion\domain\signals\models\__init__.py:START ---

--- tycherion\domain\signals\models\__init__.py:END ---

--- tycherion\ports\account.py:START ---
from __future__ import annotations

from typing import Protocol, List

from tycherion.domain.portfolio.entities import Position


class AccountPort(Protocol):
    def is_demo(self) -> bool: ...
    def balance(self) -> float: ...
    def equity(self) -> float: ...
    def positions(self) -> List[Position]: ...

--- tycherion\ports\account.py:END ---

--- tycherion\ports\market_data.py:START ---
from __future__ import annotations
from typing import Protocol
from datetime import datetime
import pandas as pd

class MarketDataPort(Protocol):
    def get_bars(self, symbol: str, timeframe: str, start: datetime, end: datetime) -> pd.DataFrame: ...

--- tycherion\ports\market_data.py:END ---

--- tycherion\ports\trading.py:START ---
from __future__ import annotations
from dataclasses import dataclass
from typing import Protocol, Optional

@dataclass
class TradeResult:
    ok: bool
    retcode: int
    order: Optional[int]
    message: str

class TradingPort(Protocol):
    def market_buy(self, symbol: str, volume: Optional[float] = None) -> TradeResult: ...
    def market_sell(self, symbol: str, volume: Optional[float] = None) -> TradeResult: ...

--- tycherion\ports\trading.py:END ---

--- tycherion\ports\universe.py:START ---
from __future__ import annotations
from typing import Protocol, List

class UniversePort(Protocol):
    def visible_symbols(self) -> List[str]: ...
    def by_pattern(self, pattern: str) -> List[str]: ...

--- tycherion\ports\universe.py:END ---

--- tycherion\ports\observability\logs.py:START ---
from __future__ import annotations

from typing import Protocol, runtime_checkable

from .types import Attributes, Severity


@runtime_checkable
class LoggerPort(Protocol):
    def emit(self, body: str, severity: Severity, attributes: Attributes | None = None) -> None: ...
    def is_enabled(self, severity: Severity) -> bool: ...


@runtime_checkable
class LoggerProviderPort(Protocol):
    def get_logger(self, name: str, version: str | None = None) -> LoggerPort: ...

--- tycherion\ports\observability\logs.py:END ---

--- tycherion\ports\observability\metrics.py:START ---
from __future__ import annotations

from typing import Protocol, runtime_checkable

from .types import Attributes


@runtime_checkable
class CounterPort(Protocol):
    def add(self, amount: int, attributes: Attributes | None = None) -> None: ...


@runtime_checkable
class MeterPort(Protocol):
    def create_counter(self, name: str, unit: str | None = None, description: str | None = None) -> CounterPort: ...


@runtime_checkable
class MeterProviderPort(Protocol):
    def get_meter(self, name: str, version: str | None = None) -> MeterPort: ...

--- tycherion\ports\observability\metrics.py:END ---

--- tycherion\ports\observability\observability.py:START ---
from __future__ import annotations

from typing import Protocol, runtime_checkable

from .logs import LoggerProviderPort
from .metrics import MeterProviderPort
from .traces import TracerProviderPort


@runtime_checkable
class ObservabilityPort(Protocol):
    @property
    def traces(self) -> TracerProviderPort: ...

    @property
    def logs(self) -> LoggerProviderPort: ...

    @property
    def metrics(self) -> MeterProviderPort: ...

    def shutdown(self) -> None: ...
    def force_flush(self) -> None: ...

--- tycherion\ports\observability\observability.py:END ---

--- tycherion\ports\observability\semconv.py:START ---
"""Tycherion observability semantic conventions.

These constants keep attribute keys and common span/event names in one place
so instrumentation stays consistent while remaining independent from the
OpenTelemetry SDK.
"""

# Resource attributes
SERVICE_NAME = "service.name"
SERVICE_INSTANCE_ID = "service.instance.id"
DEPLOYMENT_ENVIRONMENT = "deployment.environment"
TYCHERION_RUNNER_ID = "tycherion.runner_id"
TYCHERION_RUN_ID = "tycherion.run_id"
TYCHERION_SCHEMA_VERSION = "tycherion.schema_version"

# Span names (prefixed to avoid collisions across services)
SPAN_BOOTSTRAP_DISCOVER = "tycherion.bootstrap.discover"
SPAN_PIPELINE = "tycherion.pipeline"
SPAN_COVERAGE_FETCH = "tycherion.coverage.fetch"
SPAN_ALLOCATOR = "tycherion.allocator"
SPAN_BALANCER = "tycherion.balancer"
SPAN_EXECUTION = "tycherion.execution"
SPAN_RUN = "tycherion.run"

# Event names (prefixed)
EVT_PIPELINE_STAGE_STARTED = "tycherion.pipeline.stage_started"
EVT_PIPELINE_STAGE_COMPLETED = "tycherion.pipeline.stage_completed"
EVT_PIPELINE_SUMMARY = "tycherion.pipeline.summary"
EVT_PIPELINE_RUN_SUMMARY = "tycherion.pipeline.run_summary"
EVT_COVERAGE_SUMMARY = "tycherion.coverage.summary"
EVT_ALLOCATOR_COMPLETED = "tycherion.allocator.completed"
EVT_REBALANCE_PLAN_BUILT = "tycherion.rebalance.plan_built"
EVT_ORDERS_BUILT = "tycherion.orders.built"

# Common attribute keys
ATTR_CHANNEL = "tycherion.channel"
ATTR_SYMBOL = "symbol"
ATTR_STAGE = "stage"
ATTR_SCORE = "score"
ATTR_THRESHOLD = "threshold"
ATTR_CONFIG_HASH = "config_hash"
ATTR_CONFIG_PATH = "config_path"
ATTR_RUN_MODE = "run_mode"

--- tycherion\ports\observability\semconv.py:END ---

--- tycherion\ports\observability\traces.py:START ---
from __future__ import annotations

from contextlib import AbstractContextManager
from typing import Protocol, runtime_checkable

from .types import Attributes


@runtime_checkable
class SpanPort(Protocol):
    def set_attribute(self, key: str, value: object) -> None: ...
    def set_attributes(self, attributes: Attributes) -> None: ...
    def add_event(self, name: str, attributes: Attributes | None = None) -> None: ...
    def record_exception(self, exc: BaseException) -> None: ...
    def set_status_ok(self) -> None: ...
    def set_status_error(self, message: str | None = None) -> None: ...
    def is_recording(self) -> bool: ...


@runtime_checkable
class TracerPort(Protocol):
    def start_as_current_span(
        self, name: str, attributes: Attributes | None = None
    ) -> AbstractContextManager[SpanPort]:
        ...


@runtime_checkable
class TracerProviderPort(Protocol):
    def get_tracer(self, name: str, version: str | None = None) -> TracerPort: ...

--- tycherion\ports\observability\traces.py:END ---

--- tycherion\ports\observability\types.py:START ---
from __future__ import annotations

from enum import Enum
from typing import Mapping, Sequence, Union

# OpenTelemetry attribute values are limited to primitives and sequences of primitives.
AttributePrimitive = Union[bool, str, int, float]
AttributeValue = Union[AttributePrimitive, Sequence[AttributePrimitive]]
Attributes = Mapping[str, AttributeValue]

# NOTE:
# Tycherion schema version for observability payloads. Keep stable and explicit.
TYCHERION_SCHEMA_VERSION = "v3"


class Severity(str, Enum):
    TRACE = "TRACE"
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARN = "WARN"
    ERROR = "ERROR"
    FATAL = "FATAL"

    def to_logging_level(self) -> int:
        import logging

        return {
            Severity.TRACE: 5,  # custom level (below DEBUG)
            Severity.DEBUG: logging.DEBUG,
            Severity.INFO: logging.INFO,
            Severity.WARN: logging.WARNING,
            Severity.ERROR: logging.ERROR,
            Severity.FATAL: logging.CRITICAL,
        }[self]


class SpanStatus(str, Enum):
    UNSET = "UNSET"
    OK = "OK"
    ERROR = "ERROR"

--- tycherion\ports\observability\types.py:END ---

--- tycherion\ports\observability\__init__.py:START ---

--- tycherion\ports\observability\__init__.py:END ---

--- tycherion\shared\config.py:START ---
from __future__ import annotations
from pydantic import BaseModel, field_validator
from typing import Optional, Any
import os, yaml
from dotenv import load_dotenv

class Trading(BaseModel):
    dry_run: bool = True
    require_demo: bool = True
    deviation_points: int = 10
    volume_mode: str = "min"     # 'min' | 'fixed'
    fixed_volume: float = 0.01

class Risk(BaseModel):
    risk_per_trade_pct: float = 0.5
    max_daily_loss_pct: float = 2.0

class MT5(BaseModel):
    terminal_path: Optional[str] = None
    server: Optional[str] = None
    login: Optional[int] = None
    password: Optional[str] = None

class RunMode(BaseModel):
    name: str = "live_multimodel"

class ScheduleCfg(BaseModel):
    run_forever: bool = False
    interval_seconds: int = 60

class CoverageCfg(BaseModel):
    source: str = "market_watch"
    symbols: list[str] = []
    pattern: str | None = None


class PipelineStageCfg(BaseModel):
    """Configuration of a single stage in the model pipeline."""

    name: str
    drop_threshold: float | None = None


class ModelsCfg(BaseModel):
    """Application-level model selection.

    `pipeline` defines an ordered list of models to run per symbol. The order
    is the order of execution. Each stage can optionally define a
    `drop_threshold` used to discard non-held symbols early.
    """

    pipeline: list[PipelineStageCfg] = []

    @field_validator("pipeline", mode="before")
    @classmethod
    def _coerce_pipeline(cls, v: Any):
        # Accept both:
        # - pipeline: ["trend_following", "mean_reversion"]
        # - pipeline: [{name: "...", drop_threshold: ...}, ...]
        if v is None:
            return []
        if isinstance(v, list):
            out: list[Any] = []
            for item in v:
                if isinstance(item, str):
                    out.append({"name": item})
                else:
                    out.append(item)
            return out
        return v


class PortfolioCfg(BaseModel):
    allocator: str = "proportional"     # plugin name
    balancer: str = "threshold"         # plugin name
    threshold_weight: float = 0.25      # only rebalance if |w| >= threshold

class ApplicationCfg(BaseModel):
    run_mode: RunMode = RunMode()
    playbook: str = "default"
    schedule: ScheduleCfg = ScheduleCfg()
    coverage: CoverageCfg = CoverageCfg()
    models: ModelsCfg = ModelsCfg()
    portfolio: PortfolioCfg = PortfolioCfg()


class ObservabilityCfg(BaseModel):
    """Observability/OTel configuration used by bootstrap/application."""

    # Console sink (dev)
    console_enabled: bool = False
    console_channels: list[str] = ["ops"]
    console_min_level: str = "INFO"
    log_format: str = "pretty"  # pretty | json

    # OTLP export (Collector/Alloy)
    otlp_enabled: bool = False
    otlp_endpoint: str = "http://localhost:4317"
    otlp_protocol: str = "grpc"  # grpc|http
    otlp_headers: str | None = None
    otlp_insecure: bool | None = None  # None => infer from scheme

    # Deployment metadata
    deployment_env: str | None = None



class AppConfig(BaseModel):
    timeframe: str
    lookback_days: int
    trading: Trading = Trading()
    risk: Risk = Risk()
    mt5: MT5 = MT5()
    application: ApplicationCfg = ApplicationCfg()
    observability: ObservabilityCfg = ObservabilityCfg()
    telemetry: ObservabilityCfg | None = None  # backward compat

def load_config(path: str) -> AppConfig:
    load_dotenv(override=False)
    import pathlib
    p = pathlib.Path(path)
    if not p.exists():
        raise FileNotFoundError(f"Config not found: {path}")
    with open(path, "r", encoding="utf-8") as f:
        raw = yaml.safe_load(f) or {}
    raw.setdefault("mt5", {})
    mt5_cfg = raw["mt5"] or {}

    def coalesce(yaml_val, env_val):
        return env_val if (yaml_val in (None, "", 0) and env_val not in (None, "")) else yaml_val

    env_terminal = os.getenv("MT5_TERMINAL_PATH")
    env_server   = os.getenv("MT5_SERVER")
    env_login    = os.getenv("MT5_LOGIN")
    env_pass     = os.getenv("MT5_PASSWORD")

    mt5_cfg["terminal_path"] = coalesce(mt5_cfg.get("terminal_path"), env_terminal)
    mt5_cfg["server"]        = coalesce(mt5_cfg.get("server"),        env_server)
    mt5_cfg["login"]         = coalesce(mt5_cfg.get("login"),         int(env_login) if env_login and env_login.isdigit() else None)
    mt5_cfg["password"]      = coalesce(mt5_cfg.get("password"),      env_pass)


    # Observability env overrides (kept here to avoid leaking infra details into domain/application)
    # Support legacy 'telemetry' key as alias.
    raw.setdefault("observability", raw.get("telemetry", {}))
    obs_cfg = raw["observability"] or {}

    def env_bool(name: str) -> bool | None:
        v = os.getenv(name)
        if v is None:
            return None
        v = str(v).strip().lower()
        if v in ("1", "true", "yes", "y", "on"):
            return True
        if v in ("0", "false", "no", "n", "off"):
            return False
        return None

    def env_override(yaml_val, env_val):
        return env_val if env_val is not None else yaml_val

    obs_cfg["otlp_enabled"] = env_override(obs_cfg.get("otlp_enabled"), env_bool("TYCHERION_OTLP_ENABLED"))
    obs_cfg["otlp_endpoint"] = env_override(obs_cfg.get("otlp_endpoint"), os.getenv("TYCHERION_OTLP_ENDPOINT"))
    obs_cfg["otlp_protocol"] = env_override(obs_cfg.get("otlp_protocol"), os.getenv("TYCHERION_OTLP_PROTOCOL"))
    obs_cfg["otlp_headers"] = env_override(obs_cfg.get("otlp_headers"), os.getenv("TYCHERION_OTLP_HEADERS"))
    obs_cfg["otlp_insecure"] = env_override(obs_cfg.get("otlp_insecure"), env_bool("TYCHERION_OTLP_INSECURE"))
    obs_cfg["deployment_env"] = env_override(obs_cfg.get("deployment_env"), os.getenv("TYCHERION_DEPLOYMENT_ENV"))
    obs_cfg["log_format"] = env_override(obs_cfg.get("log_format"), os.getenv("TYCHERION_LOG_FORMAT"))

    # Console output for local dev
    obs_cfg["console_enabled"] = env_override(obs_cfg.get("console_enabled"), env_bool("TYCHERION_CONSOLE_ENABLED"))
    obs_cfg["console_min_level"] = env_override(obs_cfg.get("console_min_level"), os.getenv("TYCHERION_CONSOLE_MIN_LEVEL"))
    obs_cfg["console_channels"] = env_override(obs_cfg.get("console_channels"), obs_cfg.get("console_channels"))

    raw["observability"] = obs_cfg
    if "telemetry" in raw and raw["telemetry"] and "observability" not in raw:
        print("[tycherion] WARNING: 'telemetry' config is deprecated; use 'observability'.")

    raw["mt5"] = mt5_cfg
    return AppConfig.model_validate(raw)

--- tycherion\shared\config.py:END ---

--- tycherion\shared\decorators.py:START ---
from __future__ import annotations
from functools import wraps
import logging
import MetaTrader5 as mt5

_log = logging.getLogger(__name__)

def demo_only(fn):
    @wraps(fn)
    def wrapper(self, *args, **kwargs):
        require = getattr(self, "require_demo", True)
        if require:
            ai = mt5.account_info()
            if not ai or ai.trade_mode != mt5.ACCOUNT_TRADE_MODE_DEMO:
                raise RuntimeError("Blocked: only allowed in DEMO account.")
        return fn(self, *args, **kwargs)
    return wrapper

def logged(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        name = fn.__qualname__
        try:
            res = fn(*args, **kwargs)
            _log.debug("%s: ok -> %s", name, res)
            return res
        except Exception as e:
            _log.exception("%s: error", name)
            raise
    return wrapper

--- tycherion\shared\decorators.py:END ---
