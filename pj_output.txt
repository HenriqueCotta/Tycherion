Tycherion
├── >>> .env <<<
├── >>> .env.example <<<
├── .git (ignored)
├── .gitignore (ignored)
├── .venv (ignored)
├── .vscode
│   └── >>> settings.json <<<
├── README.md (ignored)
├── configs
│   └── >>> demo.yaml <<<
├── pj_output.txt (ignored)
├── >>> pyproject.toml <<<
├── >>> requirements.txt <<<
├── scripts
│   └── >>> run_demo.py <<<
├── src
│   └── tycherion
│       ├── adapters
│       │   ├── mt5
│       │   │   ├── __pycache__ (ignored)
│       │   │   ├── >>> account_mt5.py <<<
│       │   │   ├── >>> market_data_mt5.py <<<
│       │   │   ├── >>> trading_mt5.py <<<
│       │   │   └── >>> universe_mt5.py <<<
│       │   └── telemetry
│       │       ├── >>> __init__.py <<<
│       │       ├── __pycache__ (ignored)
│       │       ├── >>> console.py <<<
│       │       ├── >>> db_journal.py <<<
│       │       └── >>> memory.py <<<
│       ├── application
│       │   ├── pipeline
│       │   │   ├── >>> __init__.py <<<
│       │   │   ├── __pycache__ (ignored)
│       │   │   ├── >>> config.py <<<
│       │   │   ├── >>> result.py <<<
│       │   │   └── >>> service.py <<<
│       │   ├── plugins
│       │   │   ├── __pycache__ (ignored)
│       │   │   └── >>> registry.py <<<
│       │   ├── runmodes
│       │   │   ├── __pycache__ (ignored)
│       │   │   └── >>> live_multimodel.py <<<
│       │   ├── services
│       │   │   ├── __pycache__ (ignored)
│       │   │   ├── >>> coverage_selector.py <<<
│       │   │   ├── >>> ensemble.py <<<
│       │   │   ├── >>> order_planner.py <<<
│       │   │   └── >>> sizer.py <<<
│       │   └── telemetry
│       │       ├── >>> __init__.py <<<
│       │       ├── __pycache__ (ignored)
│       │       ├── >>> event_factory.py <<<
│       │       ├── >>> hub.py <<<
│       │       └── >>> run_context.py <<<
│       ├── bootstrap
│       │   ├── __pycache__ (ignored)
│       │   └── >>> main.py <<<
│       ├── domain
│       │   ├── >>> __init__.py <<<
│       │   ├── __pycache__ (ignored)
│       │   ├── market
│       │   │   ├── >>> __init__.py <<<
│       │   │   └── >>> entities.py <<<
│       │   ├── portfolio
│       │   │   ├── >>> __init__.py <<<
│       │   │   ├── __pycache__ (ignored)
│       │   │   ├── allocators
│       │   │   │   ├── >>> __init__.py <<<
│       │   │   │   ├── __pycache__ (ignored)
│       │   │   │   ├── >>> base.py <<<
│       │   │   │   ├── >>> equal_weight.py <<<
│       │   │   │   └── >>> proportional.py <<<
│       │   │   ├── balancers
│       │   │   │   ├── >>> __init__.py <<<
│       │   │   │   ├── __pycache__ (ignored)
│       │   │   │   ├── >>> base.py <<<
│       │   │   │   └── >>> threshold.py <<<
│       │   │   └── >>> entities.py <<<
│       │   └── signals
│       │       ├── >>> __init__.py <<<
│       │       ├── __pycache__ (ignored)
│       │       ├── >>> entities.py <<<
│       │       ├── indicators
│       │       │   ├── >>> __init__.py <<<
│       │       │   ├── __pycache__ (ignored)
│       │       │   ├── >>> base.py <<<
│       │       │   ├── >>> stretch_zscore.py <<<
│       │       │   ├── >>> trend_donchian.py <<<
│       │       │   └── >>> volatility_atr.py <<<
│       │       └── models
│       │           ├── >>> __init__.py <<<
│       │           ├── __pycache__ (ignored)
│       │           ├── >>> base.py <<<
│       │           ├── >>> mean_reversion.py <<<
│       │           └── >>> trend_following.py <<<
│       ├── ports
│       │   ├── __pycache__ (ignored)
│       │   ├── >>> account.py <<<
│       │   ├── >>> market_data.py <<<
│       │   ├── >>> telemetry.py <<<
│       │   ├── >>> trading.py <<<
│       │   └── >>> universe.py <<<
│       └── shared
│           ├── __pycache__ (ignored)
│           ├── >>> config.py <<<
│           └── >>> decorators.py <<<
├── tests
│   └── >>> test_telemetry.py <<<
└── tycherion_guidelines.md (ignored)



--- .env:START ---
MT5_TERMINAL_PATH="C:\\Program Files\\MetaTrader 5 Terminal\\terminal64.exe"

# DEMO
MT5_SERVER="Rico-DEMO"
MT5_LOGIN="3008317111"
MT5_PASSWORD="BusterBD001."

# # PROD
# MT5_SERVER="Rico-PROD"
# MT5_LOGIN="3008317111"
# MT5_PASSWORD="BusterBD001."
--- .env:END ---

--- .env.example:START ---
# Opcional: se quiser logar via código em vez do Terminal já autenticado
MT5_TERMINAL_PATH=
MT5_SERVER=
MT5_LOGIN=
MT5_PASSWORD=

--- .env.example:END ---

--- pyproject.toml:START ---
[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "tycherion"
version = "0.1.0"
requires-python = ">=3.10"
dependencies = [
  "MetaTrader5>=5.0",
  "pandas>=2.2",
  "pyyaml>=6.0",
  "python-dotenv>=1.0",
  "pydantic>=2.8",
  "typing-extensions>=4.12"
]

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]

[tool.mypy]
python_version = "3.10"
strict = true

[tool.ruff]
line-length = 100

--- pyproject.toml:END ---

--- requirements.txt:START ---
MetaTrader5>=5.0
pandas>=2.2
pyyaml>=6.0
python-dotenv>=1.0
pydantic>=2.8
typing-extensions>=4.12

--- requirements.txt:END ---

--- .vscode\settings.json:START ---
{
    "python.analysis.extraPaths": [
        "./src"
    ]
}
--- .vscode\settings.json:END ---

--- configs\demo.yaml:START ---
timeframe: "H1"

lookback_days: 15

trading:
  dry_run: true
  require_demo: true
  deviation_points: 10
  volume_mode: "min"
  fixed_volume: 100.0

risk:
  risk_per_trade_pct: 0.5
  max_daily_loss_pct: 2.0

mt5:
  terminal_path: null
  server: null
  login: null
  password: null

application:
  run_mode:
    name: "live_multimodel"
  playbook: "default"
  schedule:
    run_forever: true
    interval_seconds: 60

  coverage:
    source: "static"
    symbols: ["PETR4", "VALE3", "WIN$", "WDO$"]
    pattern: null

  models:
    pipeline:
      - "trend_following"
      - "mean_reversion"

  portfolio:
    allocator: "proportional"
    balancer: "threshold"
    threshold_weight: 0.25

telemetry:
  db_enabled: false
  db_min_level: "INFO"
  db_channels: ["audit", "ops"]        # adicione "debug" se quiser persistir debug
  db_batch_size: 50
  # db_path: "./data/execution_journal.sqlite3"  # opcional

  console_enabled: true
  console_min_level: "INFO"
  console_channels: ["ops"]            # adicione "debug" para ver debug no terminal

--- configs\demo.yaml:END ---

--- scripts\run_demo.py:START ---
import sys, pathlib
ROOT = pathlib.Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT / "src"))
from tycherion.bootstrap.main import run_app
if __name__ == "__main__":
    run_app(config_path=str(ROOT / "configs" / "demo.yaml"))

--- scripts\run_demo.py:END ---

--- src\tycherion\adapters\mt5\account_mt5.py:START ---
from __future__ import annotations

import MetaTrader5 as mt5

from tycherion.ports.account import AccountPort
from tycherion.domain.portfolio.entities import Position


class MT5Account(AccountPort):
    def is_demo(self) -> bool:
        ai = mt5.account_info()
        return bool(ai and ai.trade_mode == mt5.ACCOUNT_TRADE_MODE_DEMO)

    def balance(self) -> float:
        ai = mt5.account_info()
        return float(getattr(ai, "balance", 0.0) or 0.0)

    def equity(self) -> float:
        ai = mt5.account_info()
        return float(getattr(ai, "equity", 0.0) or 0.0)

    def positions(self) -> list[Position]:
        poss = mt5.positions_get()
        out: list[Position] = []
        if poss:
            for p in poss:
                out.append(
                    Position(
                        symbol=p.symbol,
                        quantity=float(getattr(p, "volume", 0.0) or 0.0),
                        price=float(getattr(p, "price_open", 0.0) or 0.0),
                    )
                )
        return out

--- src\tycherion\adapters\mt5\account_mt5.py:END ---

--- src\tycherion\adapters\mt5\market_data_mt5.py:START ---
from __future__ import annotations
from datetime import datetime, timezone
from typing import Dict
import pandas as pd
import MetaTrader5 as mt5
from tycherion.ports.market_data import MarketDataPort

_TF_MAP: Dict[str, int] = {
    "M1": mt5.TIMEFRAME_M1,
    "M5": mt5.TIMEFRAME_M5,
    "M15": mt5.TIMEFRAME_M15,
    "M30": mt5.TIMEFRAME_M30,
    "H1": mt5.TIMEFRAME_H1,
    "H4": mt5.TIMEFRAME_H4,
    "D1": mt5.TIMEFRAME_D1,
}

class MT5MarketData(MarketDataPort):
    def get_bars(self, symbol: str, timeframe: str, start: datetime, end: datetime) -> pd.DataFrame:
        tf = _TF_MAP.get(timeframe.upper())
        if tf is None:
            raise ValueError(f"Unsupported timeframe: {timeframe}")
        rates = mt5.copy_rates_range(
            symbol, tf,
            start.astimezone(timezone.utc),
            end.astimezone(timezone.utc)
        )
        if rates is None or len(rates) == 0:
            return pd.DataFrame(columns=["time","open","high","low","close","tick_volume","spread","real_volume"])
        df = pd.DataFrame(rates)
        df["time"] = pd.to_datetime(df["time"], unit="s", utc=True)
        return df
--- src\tycherion\adapters\mt5\market_data_mt5.py:END ---

--- src\tycherion\adapters\mt5\trading_mt5.py:START ---
from __future__ import annotations
from dataclasses import dataclass
from typing import Optional
import MetaTrader5 as mt5
from tycherion.ports.trading import TradingPort, TradeResult
from tycherion.shared.decorators import demo_only, logged
from tycherion.application.services.sizer import symbol_min_volume, volume_from_weight

@dataclass
class MT5Trader(TradingPort):
    dry_run: bool = True
    require_demo: bool = True
    deviation_points: int = 10
    volume_mode: str = "min"
    fixed_volume: float = 0.01

    def _resolve_volume(self, symbol: str, volume: Optional[float]) -> float:
        if volume is not None:
            return float(volume)
        return volume_from_weight(symbol, 1.0, self.volume_mode, self.fixed_volume)

    @logged
    @demo_only
    def market_buy(self, symbol: str, volume: Optional[float] = None) -> TradeResult:
        if self.dry_run:
            return TradeResult(True, 0, None, "DRY_RUN: buy skipped")
        if not mt5.symbol_select(symbol, True):
            return TradeResult(False, -1, None, f"symbol_select failed: {symbol}")
        tick = mt5.symbol_info_tick(symbol)
        if not tick:
            return TradeResult(False, -2, None, "missing tick")
        vol = self._resolve_volume(symbol, volume)
        if vol < symbol_min_volume(symbol):
            vol = symbol_min_volume(symbol)
        request = {
            "action": mt5.TRADE_ACTION_DEAL,
            "symbol": symbol,
            "type": mt5.ORDER_TYPE_BUY,
            "volume": vol,
            "price": tick.ask,
            "deviation": self.deviation_points,
            "type_time": mt5.ORDER_TIME_GTC,
            "type_filling": mt5.ORDER_FILLING_RETURN,
            "magic": 401,
            "comment": "tycherion-buy",
        }
        check = mt5.order_check(request)
        if not check or check.retcode != mt5.TRADE_RETCODE_DONE:
            return TradeResult(False, getattr(check, "retcode", -3), None, f"order_check failed: {check}")
        res = mt5.order_send(request)
        ok = bool(res and res.retcode in (mt5.TRADE_RETCODE_DONE, mt5.TRADE_RETCODE_PLACED))
        return TradeResult(ok, getattr(res, "retcode", -4), getattr(res, "order", None), str(res))

    @logged
    @demo_only
    def market_sell(self, symbol: str, volume: Optional[float] = None) -> TradeResult:
        if self.dry_run:
            return TradeResult(True, 0, None, "DRY_RUN: sell skipped")
        if not mt5.symbol_select(symbol, True):
            return TradeResult(False, -1, None, f"symbol_select failed: {symbol}")
        tick = mt5.symbol_info_tick(symbol)
        if not tick:
            return TradeResult(False, -2, None, "missing tick")
        vol = self._resolve_volume(symbol, volume)
        if vol < symbol_min_volume(symbol):
            vol = symbol_min_volume(symbol)
        request = {
            "action": mt5.TRADE_ACTION_DEAL,
            "symbol": symbol,
            "type": mt5.ORDER_TYPE_SELL,
            "volume": vol,
            "price": tick.bid,
            "deviation": self.deviation_points,
            "type_time": mt5.ORDER_TIME_GTC,
            "type_filling": mt5.ORDER_FILLING_RETURN,
            "magic": 401,
            "comment": "tycherion-sell",
        }
        check = mt5.order_check(request)
        if not check or check.retcode != mt5.TRADE_RETCODE_DONE:
            return TradeResult(False, getattr(check, "retcode", -3), None, f"order_check failed: {check}")
        res = mt5.order_send(request)
        ok = bool(res and res.retcode in (mt5.TRADE_RETCODE_DONE, mt5.TRADE_RETCODE_PLACED))
        return TradeResult(ok, getattr(res, "retcode", -4), getattr(res, "order", None), str(res))

--- src\tycherion\adapters\mt5\trading_mt5.py:END ---

--- src\tycherion\adapters\mt5\universe_mt5.py:START ---
from __future__ import annotations
import MetaTrader5 as mt5
from typing import List
from tycherion.ports.universe import UniversePort

class MT5Universe(UniversePort):
    def visible_symbols(self) -> List[str]:
        syms = mt5.symbols_get()
        return [s.name for s in syms if getattr(s, "visible", False)]

    def by_pattern(self, pattern: str) -> List[str]:
        syms = mt5.symbols_get(pattern)
        return [s.name for s in syms]

--- src\tycherion\adapters\mt5\universe_mt5.py:END ---

--- src\tycherion\adapters\telemetry\console.py:START ---
from __future__ import annotations

import sys
from dataclasses import dataclass, field
from typing import Any, Mapping

from tycherion.ports.telemetry import TelemetryEvent, TelemetryLevel, TelemetrySink


def _short(v: Any, limit: int = 80) -> str:
    s = str(v)
    return s if len(s) <= limit else (s[: limit - 1] + "…")


def _summarize(event: TelemetryEvent) -> str:
    scope = dict(event.scope or {})
    payload = dict(event.payload or {})

    # Prefer common identifiers
    parts: list[str] = []
    for k in ("stage", "symbol", "model"):
        if k in scope and scope[k] not in (None, ""):
            parts.append(f"{k}={_short(scope[k], 40)}")

    # Add a small, curated payload summary
    for k in (
        "dropped_count",
        "passed_count",
        "symbols_count",
        "duration_ms",
        "threshold",
        "score",
        "side",
        "weight",
        "confidence",
        "reason",
    ):
        if k in payload:
            parts.append(f"{k}={_short(payload[k], 40)}")

    # If nothing matched, expose payload keys (but not full payload)
    if not parts and payload:
        parts.append(f"payload_keys={list(payload.keys())[:8]}")

    return " ".join(parts)


@dataclass(slots=True)
class ConsoleTelemetrySink(TelemetrySink):
    """Human-friendly console output.

    Default should be disabled via config. When enabled, prints one line per event.
    """

    enabled_flag: bool = False
    channels: set[str] = field(default_factory=lambda: {"ops"})
    min_level: TelemetryLevel = TelemetryLevel.INFO
    stream: Any = sys.stdout

    def enabled(self, channel: str, level: TelemetryLevel, name: str | None = None) -> bool:
        _ = name
        if not self.enabled_flag:
            return False
        if channel not in self.channels:
            return False
        return TelemetryLevel.coerce(level).rank() >= TelemetryLevel.coerce(self.min_level).rank()

    def emit(self, event: TelemetryEvent) -> None:
        # Keep this stable and easy to grep
        msg = (
            f"[{event.level.value}]"
            f"[{event.channel}]"
            f"[{event.run_id}] "
            f"{event.name}"
        )
        summary = _summarize(event)
        if summary:
            msg = f"{msg} {summary}"
        try:
            self.stream.write(msg + "\n")
            self.stream.flush()
        except Exception:
            return

--- src\tycherion\adapters\telemetry\console.py:END ---

--- src\tycherion\adapters\telemetry\db_journal.py:START ---
from __future__ import annotations

import json
import sqlite3
from dataclasses import dataclass, field
from pathlib import Path

from tycherion.ports.telemetry import TelemetryEvent, TelemetryLevel, TelemetrySink


_DDL = """
CREATE TABLE IF NOT EXISTS execution_journal_events (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  ts_utc TEXT NOT NULL,
  run_id TEXT NOT NULL,
  name TEXT NOT NULL,
  level TEXT NOT NULL,
  channel TEXT NOT NULL,
  scope_json TEXT NOT NULL,
  payload_json TEXT NOT NULL
);
CREATE INDEX IF NOT EXISTS idx_eje_run_ts ON execution_journal_events(run_id, ts_utc);
CREATE INDEX IF NOT EXISTS idx_eje_name ON execution_journal_events(name);
CREATE INDEX IF NOT EXISTS idx_eje_channel ON execution_journal_events(channel);
"""


@dataclass(slots=True)
class DbExecutionJournalSink(TelemetrySink):
    """Append-only execution journal persisted in SQLite."""

    db_path: str
    enabled_flag: bool = True
    channels: set[str] = field(default_factory=lambda: {"audit", "ops"})
    min_level: TelemetryLevel = TelemetryLevel.INFO
    batch_size: int = 50

    _conn: sqlite3.Connection | None = field(default=None, init=False, repr=False)
    _buffer: list[tuple[str, str, str, str, str, str, str]] = field(
        default_factory=list, init=False, repr=False
    )

    def _ensure_conn(self) -> sqlite3.Connection:
        if self._conn is not None:
            return self._conn
        p = Path(self.db_path)
        p.parent.mkdir(parents=True, exist_ok=True)
        conn = sqlite3.connect(str(p))
        conn.execute("PRAGMA journal_mode=WAL;")
        conn.executescript(_DDL)
        conn.commit()
        self._conn = conn
        return conn

    def enabled(self, channel: str, level: TelemetryLevel, name: str | None = None) -> bool:
        _ = name
        if not self.enabled_flag:
            return False
        if channel not in self.channels:
            return False
        return TelemetryLevel.coerce(level).rank() >= TelemetryLevel.coerce(self.min_level).rank()

    def emit(self, event: TelemetryEvent) -> None:
        conn = self._ensure_conn()
        scope_json = json.dumps(dict(event.scope or {}), separators=(",", ":"), ensure_ascii=False)
        payload_json = json.dumps(dict(event.payload or {}), separators=(",", ":"), ensure_ascii=False)
        row = (
            event.ts_utc.isoformat(),
            str(event.run_id),
            str(event.name),
            str(event.level.value),
            str(event.channel),
            scope_json,
            payload_json,
        )
        self._buffer.append(row)
        if len(self._buffer) >= max(1, int(self.batch_size)):
            self.flush()

    def flush(self) -> None:
        if not self._buffer:
            return
        conn = self._ensure_conn()
        rows = list(self._buffer)
        self._buffer.clear()
        try:
            conn.executemany(
                """
                INSERT INTO execution_journal_events
                  (ts_utc, run_id, name, level, channel, scope_json, payload_json)
                VALUES (?, ?, ?, ?, ?, ?, ?)
                """,
                rows,
            )
            conn.commit()
        except Exception:
            # best effort; do not break the run
            return

    def close(self) -> None:
        try:
            self.flush()
        finally:
            if self._conn is not None:
                try:
                    self._conn.close()
                except Exception:
                    pass
                self._conn = None

--- src\tycherion\adapters\telemetry\db_journal.py:END ---

--- src\tycherion\adapters\telemetry\memory.py:START ---
from __future__ import annotations

from dataclasses import dataclass, field
from typing import Iterable

from tycherion.ports.telemetry import TelemetryEvent, TelemetryLevel, TelemetrySink


@dataclass(slots=True)
class InMemoryTelemetrySink(TelemetrySink):
    """Test-friendly telemetry sink.

    Stores events in memory so tests can assert on them without stdout/DB.
    """

    enabled_flag: bool = True
    channels: set[str] = field(default_factory=lambda: {"audit", "ops"})
    min_level: TelemetryLevel = TelemetryLevel.INFO
    events: list[TelemetryEvent] = field(default_factory=list)

    def enabled(self, channel: str, level: TelemetryLevel, name: str | None = None) -> bool:
        _ = name
        if not self.enabled_flag:
            return False
        if channel not in self.channels:
            return False
        return TelemetryLevel.coerce(level).rank() >= TelemetryLevel.coerce(self.min_level).rank()

    def emit(self, event: TelemetryEvent) -> None:
        self.events.append(event)

--- src\tycherion\adapters\telemetry\memory.py:END ---

--- src\tycherion\adapters\telemetry\__init__.py:START ---
from .console import ConsoleTelemetrySink
from .db_journal import DbExecutionJournalSink
from .memory import InMemoryTelemetrySink

__all__ = [
    "ConsoleTelemetrySink",
    "DbExecutionJournalSink",
    "InMemoryTelemetrySink",
]

--- src\tycherion\adapters\telemetry\__init__.py:END ---

--- src\tycherion\application\pipeline\config.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from typing import Iterable, List

from tycherion.shared.config import AppConfig, PipelineStageCfg


@dataclass(frozen=True, slots=True)
class PipelineStageConfig:
    """Configuration of a single pipeline stage (application-level, YAML-agnostic)."""

    name: str
    drop_threshold: float | None = None


@dataclass(frozen=True, slots=True)
class PipelineConfig:
    """Internal normalized pipeline configuration.

    This object is the only thing the pipeline execution should consume.
    It is intentionally decoupled from YAML and Pydantic.
    """

    stages: List[PipelineStageConfig]


def build_pipeline_config(cfg: AppConfig) -> PipelineConfig:
    """Build a PipelineConfig from the current AppConfig.

    The AppConfig is created by YAML/adapters, but the rest of the application
    should not read YAML-derived structures directly.
    """
    stages_in: Iterable[PipelineStageCfg] = cfg.application.models.pipeline or []
    stages: list[PipelineStageConfig] = []
    for st in stages_in:
        stages.append(
            PipelineStageConfig(
                name=str(st.name),
                drop_threshold=(float(st.drop_threshold) if st.drop_threshold is not None else None),
            )
        )
    if not stages:
        raise RuntimeError(
            "No model pipeline configured. Please set application.models.pipeline in your YAML."
        )
    return PipelineConfig(stages=stages)

--- src\tycherion\application\pipeline\config.py:END ---

--- src\tycherion\application\pipeline\result.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict

from tycherion.domain.portfolio.entities import SignalsBySymbol
from tycherion.domain.signals.entities import SymbolState

from .config import PipelineConfig


@dataclass(frozen=True, slots=True)
class PipelineRunResult:
    pipeline_config: PipelineConfig
    states_by_symbol: Dict[str, SymbolState]
    signals_by_symbol: SignalsBySymbol
    stage_stats: Dict[str, int]

--- src\tycherion\application\pipeline\result.py:END ---

--- src\tycherion\application\pipeline\service.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from typing import Callable, Dict, Mapping, Optional, Tuple

import pandas as pd

from tycherion.domain.portfolio.entities import PortfolioSnapshot, Signal, SignalsBySymbol
from tycherion.domain.signals.entities import (
    IndicatorOutput,
    ModelDecision,
    ModelStageResult,
    SymbolState,
)
from tycherion.domain.signals.models.base import SignalModel
from tycherion.domain.signals.indicators.base import BaseIndicator
from tycherion.ports.market_data import MarketDataPort
from tycherion.application.telemetry.run_context import RunTelemetry
from tycherion.ports.telemetry import TelemetryLevel, TelemetryPort

from .config import PipelineConfig, PipelineStageConfig
from .result import PipelineRunResult

@dataclass(slots=True)
class ModelPipelineService:
    """Façade that runs the ordered per-symbol model pipeline."""

    market_data: MarketDataPort
    model_registry: Mapping[str, SignalModel]
    indicator_picker: Callable[[str, Optional[str]], BaseIndicator]
    timeframe: str
    lookback_days: int
    playbook: str | None = None
    telemetry: TelemetryPort | None = None

    def run(
        self,
        universe_symbols: list[str],
        portfolio_snapshot: PortfolioSnapshot,
        pipeline_config: PipelineConfig,
        run_id: str,
    ) -> PipelineRunResult:
        t = RunTelemetry(port=self.telemetry, run_id=str(run_id), base_scope={"component": "pipeline"})
        held_symbols = set(portfolio_snapshot.positions.keys())

        t.emit(
            name="pipeline.started",
            channel="ops",
            level=TelemetryLevel.INFO,
            payload={
                "symbols_count": int(len(universe_symbols)),
                "stages": [st.name for st in pipeline_config.stages],
            },
        )

        # 1) Init per-symbol state
        states: Dict[str, SymbolState] = {
            sym: SymbolState(symbol=sym, is_held=(sym in held_symbols))
            for sym in universe_symbols
        }

        # 2) Resolve models
        resolved = self._resolve_models(pipeline_config)

        # 3) Determine indicator needs once for the whole pipeline
        needed_keys: set[str] = set()
        for _, model in resolved:
            try:
                needed_keys.update(model.requires() or set())
            except Exception:
                # a model might not implement requires()
                pass

        # 4) Time window for analysis
        end = datetime.now(timezone.utc)
        start = end - timedelta(days=int(self.lookback_days))

        stage_stats: Dict[str, int] = {st.name: 0 for st in pipeline_config.stages}
        stage_passed: Dict[str, int] = {st.name: 0 for st in pipeline_config.stages}

        for st in pipeline_config.stages:
            t.emit(
                name="pipeline.stage_started",
                channel="ops",
                level=TelemetryLevel.INFO,
                scope={"stage": st.name},
                payload={"threshold": st.drop_threshold},
            )

        for symbol, state in states.items():
            if not state.alive and not state.is_held:
                continue

            df = self._safe_get_bars(symbol, start, end, state, t)
            if df is None or df.empty:
                if not state.is_held:
                    t.emit(
                        name="pipeline.symbol_dropped",
                        channel="audit",
                        level=TelemetryLevel.WARN,
                        scope={"symbol": symbol},
                        payload={"reason": "no_market_data"},
                    )
                    state.alive = False
                continue

            if t.enabled("debug", TelemetryLevel.DEBUG):
                try:
                    t.emit(
                        name="market_data.sample",
                        channel="debug",
                        level=TelemetryLevel.DEBUG,
                        scope={"symbol": symbol},
                        payload={
                            "rows": int(len(df)),
                            "columns": list(df.columns)[:20],
                            "head": df.head(2).to_dict(orient="list"),
                            "tail": df.tail(2).to_dict(orient="list"),
                        },
                    )
                except Exception:
                    pass

            bundle = self._compute_indicators(df, needed_keys, state, t)

            # Pipeline execution per stage
            for stage_cfg, model in resolved:
                if not state.alive and not state.is_held:
                    break

                stage_passed[stage_cfg.name] = int(stage_passed.get(stage_cfg.name, 0)) + 1
                score = self._run_stage(symbol, stage_cfg, model, bundle, state, t)

                # Drop policy
                if stage_cfg.drop_threshold is not None and score < float(stage_cfg.drop_threshold):
                    if state.is_held:
                        state.notes[f"below_threshold_{stage_cfg.name}"] = 1.0
                        continue
                    state.alive = False
                    state.notes[f"dropped_by_{stage_cfg.name}"] = 1.0
                    stage_stats[stage_cfg.name] = int(stage_stats.get(stage_cfg.name, 0)) + 1
                    t.emit(
                        name="pipeline.symbol_dropped",
                        channel="audit",
                        level=TelemetryLevel.INFO,
                        scope={"symbol": symbol, "stage": stage_cfg.name},
                        payload={
                            "score": float(score),
                            "threshold": float(stage_cfg.drop_threshold),
                            "reason": "below_threshold",
                        },
                    )
                    break

            # Final signal fields (simple v1 rule: last stage score)
            last_score = float(state.pipeline_results[-1].score) if state.pipeline_results else 0.0
            state.alpha_score = last_score
            state.notes["final_confidence"] = abs(last_score)

        # 5) Convert states into SignalsBySymbol
        signals: SignalsBySymbol = {}
        for symbol, state in states.items():
            if not state.alive and not state.is_held:
                continue
            signed = float(state.alpha_score)
            confidence = float(state.notes.get("final_confidence", abs(signed)))
            signals[symbol] = Signal(symbol=symbol, signed=signed, confidence=confidence)
            t.emit(
                name="pipeline.signal_emitted",
                channel="audit",
                level=TelemetryLevel.INFO,
                scope={"symbol": symbol},
                payload={"signed": signed, "confidence": confidence},
            )

        for st in pipeline_config.stages:
            dropped = int(stage_stats.get(st.name, 0))
            passed = int(stage_passed.get(st.name, 0))
            t.emit(
                name="pipeline.stage_completed",
                channel="ops",
                level=TelemetryLevel.INFO,
                scope={"stage": st.name},
                payload={
                    "passed_count": passed,
                    "dropped_count": dropped,
                    "threshold": st.drop_threshold,
                },
            )

        t.emit(
            name="pipeline.completed",
            channel="ops",
            level=TelemetryLevel.INFO,
            payload={
                "signals_count": int(len(signals)),
                "alive_count": int(sum(1 for s in states.values() if s.alive or s.is_held)),
            },
        )

        return PipelineRunResult(
            pipeline_config=pipeline_config,
            states_by_symbol=states,
            signals_by_symbol=signals,
            stage_stats=stage_stats,
        )

    def _resolve_models(self, pipeline_config: PipelineConfig) -> list[Tuple[PipelineStageConfig, SignalModel]]:
        pipeline: list[Tuple[PipelineStageConfig, SignalModel]] = []
        for stage in pipeline_config.stages:
            name = stage.name
            model = self.model_registry.get(name)
            if model is None:
                available = ", ".join(sorted(self.model_registry.keys()))
                raise RuntimeError(f"Model not found: {name!r}. Available models: {available}")
            pipeline.append((stage, model))
        return pipeline

    def _safe_get_bars(
        self,
        symbol: str,
        start: datetime,
        end: datetime,
        state: SymbolState,
        t: RunTelemetry,
    ) -> pd.DataFrame | None:
        try:
            return self.market_data.get_bars(symbol, self.timeframe, start, end)
        except Exception as e:
            state.notes["data_error"] = 1.0
            t.emit(
                name="error.exception",
                channel="ops",
                level=TelemetryLevel.ERROR,
                scope={"symbol": symbol},
                payload={"exception_type": type(e).__name__, "message": str(e), "stage": "get_bars"},
            )
            return None

    def _compute_indicators(
        self,
        df: pd.DataFrame,
        needed_keys: set[str],
        state: SymbolState,
        t: RunTelemetry,
    ) -> Dict[str, IndicatorOutput]:
        bundle: Dict[str, IndicatorOutput] = {}
        for key in needed_keys:
            try:
                ind = self.indicator_picker(key, self.playbook)
                bundle[key] = ind.compute(df.copy())
            except Exception as e:
                state.notes[f"indicator_error_{key}"] = 1.0
                t.emit(
                    name="error.exception",
                    channel="ops",
                    level=TelemetryLevel.ERROR,
                    payload={
                        "exception_type": type(e).__name__,
                        "message": str(e),
                        "stage": "indicator",
                        "indicator": key,
                    },
                )
                bundle[key] = IndicatorOutput(score=0.0, features={})
        return bundle

    def _run_stage(
        self,
        symbol: str,
        stage_cfg: PipelineStageConfig,
        model: SignalModel,
        indicators: Dict[str, IndicatorOutput],
        state: SymbolState,
        t: RunTelemetry,
    ) -> float:
        stage_name = stage_cfg.name
        try:
            if t.enabled("debug", TelemetryLevel.DEBUG):
                try:
                    t.emit(
                        name="model.input_snapshot",
                        channel="debug",
                        level=TelemetryLevel.DEBUG,
                        scope={"symbol": symbol, "stage": stage_name, "model": stage_name},
                        payload={
                            "indicator_keys": list(indicators.keys())[:30],
                            "features_keys": {
                                k: list(v.features.keys())[:20]
                                for k, v in indicators.items()
                                if getattr(v, "features", None)
                            },
                        },
                    )
                except Exception:
                    pass
            decision = model.decide(indicators)
        except Exception as e:
            state.notes[f"model_error_{stage_name}"] = 1.0
            t.emit(
                name="error.exception",
                channel="ops",
                level=TelemetryLevel.ERROR,
                scope={"symbol": symbol, "stage": stage_name, "model": stage_name},
                payload={"exception_type": type(e).__name__, "message": str(e), "stage": "model"},
            )
            decision = ModelDecision(side="HOLD", weight=0.0, confidence=0.0)

        score = self._decision_to_score(decision)
        state.pipeline_results.append(ModelStageResult(model_name=stage_name, score=score))

        t.emit(
            name="model.decided",
            channel="audit",
            level=TelemetryLevel.INFO,
            scope={"symbol": symbol, "stage": stage_name, "model": stage_name},
            payload={
                "score": float(score),
                "side": decision.side,
                "weight": float(decision.weight or 0.0),
                "confidence": float(decision.confidence or 0.0),
            },
        )
        return score

    @staticmethod
    def _decision_to_score(d: ModelDecision) -> float:
        """Map a ModelDecision into a numeric score in [-1, 1]."""
        side = (d.side or "HOLD").upper()
        w = float(d.weight or 0.0)
        w = max(0.0, min(1.0, w))
        if side == "BUY":
            s = w
        elif side == "SELL":
            s = -w
        else:
            s = 0.0
        return max(-1.0, min(1.0, s))

    # Telemetry helper removed: use RunTelemetry wrapper for structured events.


--- src\tycherion\application\pipeline\service.py:END ---

--- src\tycherion\application\pipeline\__init__.py:START ---

--- src\tycherion\application\pipeline\__init__.py:END ---

--- src\tycherion\application\plugins\registry.py:START ---
from __future__ import annotations

from typing import Dict, List, Iterable

from tycherion.application.telemetry.event_factory import make_event
from tycherion.ports.telemetry import TelemetryLevel, TelemetryPort

from tycherion.domain.signals.indicators.base import BaseIndicator
from tycherion.domain.signals.models.base import SignalModel
from tycherion.domain.portfolio.allocators.base import BaseAllocator
from tycherion.domain.portfolio.balancers.base import BaseBalancer

INDICATORS: Dict[str, List[BaseIndicator]] = {}
MODELS: Dict[str, SignalModel] = {}
ALLOCATORS: Dict[str, BaseAllocator] = {}
BALANCERS: Dict[str, BaseBalancer] = {}
DEFAULT_METHOD: Dict[str, str] = {}

def register_indicator(*, key: str, method: str, tags: set[str]):
    """
    Register an indicator implementation for a given logical key (e.g. "trend")
    and method (e.g. "donchian_50_50").
    """
    def deco(cls):
        inst = cls()
        inst.key = key
        inst.method = method
        inst.tags = tags
        INDICATORS.setdefault(key, []).append(inst)
        return cls
    return deco


def register_model(*, name: str, tags: set[str]):
    """
    Register a per-symbol signal model.
    """
    def deco(cls):
        inst = cls()
        inst.name = name
        inst.tags = tags
        MODELS[name] = inst
        return cls
    return deco


def register_allocator(*, name: str, tags: set[str]):
    """
    Register a portfolio allocator strategy.
    """
    def deco(cls):
        inst = cls()
        inst.name = name
        inst.tags = tags
        ALLOCATORS[name] = inst
        return cls
    return deco


def register_balancer(*, name: str, tags: set[str]):
    """
    Register a portfolio balancer / rebalancer strategy.
    """
    def deco(cls):
        inst = cls()
        inst.name = name
        inst.tags = tags
        BALANCERS[name] = inst
        return cls
    return deco


def set_default_indicator_method(key: str, method: str) -> None:
    DEFAULT_METHOD[key] = method


def pick_indicator_for(key: str, playbook: str | None = None) -> BaseIndicator:
    """
    Pick an indicator instance for a given key and (optionally) playbook.
    Preference order:
    - indicators whose tags contain the playbook name
    - indicators whose tags contain "default"
    - otherwise, the first registered
    If DEFAULT_METHOD[key] is set, prefer that method among candidates.
    """
    candidates: Iterable[BaseIndicator] = INDICATORS.get(key, [])
    candidates = list(candidates)
    if not candidates:
        raise KeyError(f"No indicators registered for key={key!r}")

    # filter by tags / playbook
    if playbook:
        tagged = [
            ind for ind in candidates
            if playbook in getattr(ind, "tags", set())
        ]
        if tagged:
            candidates = tagged

    # then prefer "default"
    defaults = [
        ind for ind in candidates
        if "default" in getattr(ind, "tags", set())
    ]
    if defaults:
        candidates = defaults

    # lastly, prefer DEFAULT_METHOD if configured
    method = DEFAULT_METHOD.get(key)
    if method:
        for ind in candidates:
            if getattr(ind, "method", None) == method:
                return ind

    return candidates[0]


def auto_discover(telemetry: TelemetryPort | None) -> None:
    """
    Import all plugin modules so that their decorators run and fill the
    registries above. This is called once during application startup.
    """
    import importlib
    import pkgutil
    
    def _emit(name: str, *, level: TelemetryLevel, channel: str, payload: dict) -> None:
        if telemetry is None:
            return
        try:
            telemetry.emit(
                make_event(
                    run_id="bootstrap",
                    name=name,
                    level=level,
                    channel=channel,
                    scope={"component": "plugins"},
                    payload=payload,
                )
            )
        except Exception:
            return

    bases = (
        "tycherion.domain.signals.indicators",
        "tycherion.domain.signals.models",
        "tycherion.domain.portfolio.allocators",
        "tycherion.domain.portfolio.balancers",
    )

    for base in bases:
        try:
            pkg = importlib.import_module(base)
        except Exception as e:
            _emit(
                "plugins.base_import_failed",
                level=TelemetryLevel.WARN,
                channel="ops",
                payload={"base": base, "error": str(e)},
            )
            continue

        pkg_path = getattr(pkg, "__path__", None)
        if not pkg_path:
            continue

        for mod in pkgutil.walk_packages(pkg_path, pkg.__name__ + "."):
            try:
                importlib.import_module(mod.name)
            except Exception as e:
                _emit(
                    "plugins.module_import_failed",
                    level=TelemetryLevel.WARN,
                    channel="ops",
                    payload={"module": mod.name, "error": str(e)},
                )

    _emit(
        "plugins.discovered",
        level=TelemetryLevel.INFO,
        channel="ops",
        payload={
            "indicators_count": int(sum(len(v) for v in INDICATORS.values())),
            "models_count": int(len(MODELS)),
            "allocators_count": int(len(ALLOCATORS)),
            "balancers_count": int(len(BALANCERS)),
        },
    )

--- src\tycherion\application\plugins\registry.py:END ---

--- src\tycherion\application\runmodes\live_multimodel.py:START ---
from __future__ import annotations

import time
import uuid
from typing import Dict

from tycherion.shared.config import AppConfig
from tycherion.ports.trading import TradingPort
from tycherion.ports.account import AccountPort
from tycherion.ports.universe import UniversePort

from tycherion.application.plugins.registry import (
    ALLOCATORS,
    BALANCERS,
)
from tycherion.application.services.coverage_selector import build_coverage
from tycherion.application.services.order_planner import build_orders
from tycherion.domain.portfolio.entities import (
    PortfolioSnapshot,
    Position,
)

from tycherion.application.pipeline.config import build_pipeline_config
from tycherion.application.pipeline.service import ModelPipelineService
from tycherion.application.telemetry.run_context import RunTelemetry
from tycherion.ports.telemetry import TelemetryLevel, TelemetryPort


def _build_portfolio_snapshot(account: AccountPort) -> PortfolioSnapshot:
    equity = float(account.equity())
    positions: Dict[str, Position] = {}
    for p in account.positions():
        positions[p.symbol] = p
    return PortfolioSnapshot(equity=equity, positions=positions)


def run_live_multimodel(
    cfg: AppConfig,
    trader: TradingPort,
    account: AccountPort,
    universe: UniversePort,
    pipeline_service: ModelPipelineService,
    telemetry: TelemetryPort | None = None,
) -> None:
    """Live runmode that delegates per-symbol pipeline execution to ModelPipelineService."""

    allocator = ALLOCATORS.get(cfg.application.portfolio.allocator)
    if not allocator:
        raise RuntimeError(f"Allocator not found: {cfg.application.portfolio.allocator!r}")

    balancer = BALANCERS.get(cfg.application.portfolio.balancer)
    if not balancer:
        raise RuntimeError(f"Balancer not found: {cfg.application.portfolio.balancer!r}")

    pipeline_config = build_pipeline_config(cfg)
    # no stdout by default; this is emitted via telemetry when sinks are enabled

    def step_once() -> None:
        run_id = str(uuid.uuid4())
        t = RunTelemetry(port=telemetry, run_id=run_id, base_scope={"component": "runmode"})
        start_t = time.perf_counter()

        t.emit(
            name="run.cycle_started",
            channel="ops",
            level=TelemetryLevel.INFO,
            scope={"run_mode": "live_multimodel"},
            payload={
                "timeframe": cfg.timeframe,
                "lookback_days": int(cfg.lookback_days),
                "pipeline": [st.name for st in pipeline_config.stages],
            },
        )

        # 1) Structural universe from coverage + ensure held symbols are included
        coverage = build_coverage(cfg, pipeline_service.market_data, universe)
        portfolio = _build_portfolio_snapshot(account)
        held_symbols = set(portfolio.positions.keys())
        universe_symbols = sorted(set(coverage) | held_symbols)

        t.emit(
            name="run.coverage_built",
            channel="ops",
            level=TelemetryLevel.INFO,
            payload={
                "symbols_count": int(len(universe_symbols)),
                "symbols_sample": universe_symbols[: min(10, len(universe_symbols))],
            },
        )

        # 2) Run pipeline (single entrypoint)
        result = pipeline_service.run(
            universe_symbols=universe_symbols,
            portfolio_snapshot=portfolio,
            pipeline_config=pipeline_config,
            run_id=run_id,
        )

        t.emit(
            name="run.pipeline_finished",
            channel="ops",
            level=TelemetryLevel.INFO,
            payload={"stage_stats": dict(result.stage_stats or {})},
        )

        # 3) Allocation -> target weights
        target_alloc = allocator.allocate(result.signals_by_symbol)

        # 4) Balancing -> rebalance plan
        plan = balancer.plan(
            portfolio=portfolio,
            target=target_alloc,
            threshold=cfg.application.portfolio.threshold_weight,
        )
        t.emit(
            name="rebalance.plan_built",
            channel="ops",
            level=TelemetryLevel.INFO,
            payload={"instructions_count": int(len(plan))},
        )

        # 5) Orders -> execution
        orders = build_orders(portfolio, plan, cfg.trading)
        t.emit(
            name="orders.built",
            channel="ops",
            level=TelemetryLevel.INFO,
            payload={"orders_count": int(len(orders))},
        )

        for od in orders:
            if od.side.upper() == "BUY":
                res = trader.market_buy(od.symbol, volume=od.volume)
            else:
                res = trader.market_sell(od.symbol, volume=od.volume)
            t.emit(
                name="trade.executed",
                channel="ops",
                level=TelemetryLevel.INFO,
                scope={"symbol": od.symbol},
                payload={"side": od.side, "volume": float(od.volume), "result": str(res)},
            )

        t.emit(
            name="run.cycle_finished",
            channel="ops",
            level=TelemetryLevel.INFO,
            scope={"run_mode": "live_multimodel"},
            payload={"duration_ms": int((time.perf_counter() - start_t) * 1000)},
        )

        flush = getattr(telemetry, "flush", None)
        if callable(flush):
            try:
                flush()
            except Exception:
                pass

    if cfg.application.schedule.run_forever:
        while True:
            try:
                step_once()
                time.sleep(max(1, cfg.application.schedule.interval_seconds))
            except KeyboardInterrupt:
                t = RunTelemetry(port=telemetry, run_id="bootstrap", base_scope={"component": "runmode"})
                t.emit(
                    name="run.stopped",
                    channel="ops",
                    level=TelemetryLevel.INFO,
                    scope={"run_mode": "live_multimodel"},
                    payload={"reason": "KeyboardInterrupt"},
                )
                break
            except Exception as e:
                t = RunTelemetry(port=telemetry, run_id="bootstrap", base_scope={"component": "runmode"})
                t.emit(
                    name="error.exception",
                    channel="ops",
                    level=TelemetryLevel.ERROR,
                    scope={"run_mode": "live_multimodel"},
                    payload={"exception_type": type(e).__name__, "message": str(e)},
                )
                time.sleep(3)
    else:
        step_once()


--- src\tycherion\application\runmodes\live_multimodel.py:END ---

--- src\tycherion\application\services\coverage_selector.py:START ---
from __future__ import annotations

from tycherion.shared.config import AppConfig
from tycherion.ports.market_data import MarketDataPort
from tycherion.ports.universe import UniversePort


def _build_base_coverage(cfg: AppConfig, universe: UniversePort) -> list[str]:
    """Build the *structural* universe of symbols.

    Coverage is intentionally dumb. It only answers: *which* symbols should be
    considered, based on the configured source. Any kind of "smart filtering"
    (liquidity, regimes, sanity checks, alpha, etc.) must live in the model
    pipeline, not here.
    """
    src = (cfg.application.coverage.source or "").lower()
    if src == "static":
        # Remove duplicates while preserving order
        return list(dict.fromkeys(cfg.application.coverage.symbols or []))
    if src == "market_watch":
        return universe.visible_symbols()
    if src == "pattern":
        patt = cfg.application.coverage.pattern or "*"
        return universe.by_pattern(patt)
    return universe.visible_symbols()


def build_coverage(cfg: AppConfig, data: MarketDataPort, universe: UniversePort) -> list[str]:
    """Build the list of symbols to analyse in this run.

    NOTE: `data` is kept in the signature for backward compatibility, but is
    intentionally unused. The universe thinning that previously depended on
    recent `tick_volume` (coverage.top_n) is deprecated and removed.
    """
    _ = data  # explicit unused
    return _build_base_coverage(cfg, universe)

--- src\tycherion\application\services\coverage_selector.py:END ---

--- src\tycherion\application\services\ensemble.py:START ---
# application/services/ensemble.py (versão nova)

from __future__ import annotations

from typing import List
from tycherion.domain.signals.entities import ModelDecision, AggregatedDecision


def combine(decisions: List[ModelDecision]) -> AggregatedDecision:
    """
    Combina uma lista de ModelDecision em uma decisão agregada única.
    """
    if not decisions:
        return AggregatedDecision(
            side="HOLD",
            weight=0.0,
            confidence=0.0,
            signed=0.0,
        )

    num, den = 0.0, 0.0
    for d in decisions:
        side = (d.side or "HOLD").upper()
        w = float(d.weight)
        c = float(d.confidence if d.confidence is not None else 0.5)
        c = max(0.0, min(1.0, c))

        if side == "BUY":
            signed = w
        elif side == "SELL":
            signed = -w
        else:
            signed = 0.0

        num += signed * c
        den += c

    if den <= 0:
        return AggregatedDecision(
            side="HOLD",
            weight=0.0,
            confidence=0.0,
            signed=0.0,
        )

    s = num / den
    side = "BUY" if s > 0.1 else ("SELL" if s < -0.1 else "HOLD")
    weight = min(1.0, abs(s))
    confidence = min(1.0, den / max(1, len(decisions)))

    return AggregatedDecision(
        side=side,
        weight=weight,
        confidence=confidence,
        signed=s,
    )


--- src\tycherion\application\services\ensemble.py:END ---

--- src\tycherion\application\services\order_planner.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from typing import List

from tycherion.domain.portfolio.entities import PortfolioSnapshot, RebalanceInstruction
from tycherion.shared.config import Trading


@dataclass
class SuggestedOrder:
    symbol: str
    side: str   # "BUY" | "SELL"
    volume: float


def build_orders(
    portfolio: PortfolioSnapshot,
    plan: List[RebalanceInstruction],
    trading_cfg: Trading,
) -> List[SuggestedOrder]:
    """
    Convert domain-level rebalance instructions (expressed in weights) into
    concrete order suggestions with broker volumes. This is the point where
    we cross from the pure portfolio domain into broker-specific constraints.
    """
    # Lazy import to avoid circular deps
    from tycherion.application.services.sizer import (
        volume_from_weight,
        symbol_min_volume,
    )

    orders: List[SuggestedOrder] = []
    for instr in plan:
        # For now we scale volumes solely by absolute delta_weight. In the
        # future this can incorporate volatility, risk, etc.
        w = abs(float(instr.delta_weight))
        if w <= 0.0:
            continue

        vol = volume_from_weight(
            instr.symbol,
            w,
            trading_cfg.volume_mode,
            trading_cfg.fixed_volume,
        )
        min_vol = symbol_min_volume(instr.symbol)
        vol = max(vol, min_vol)
        if vol <= 0.0:
            continue

        orders.append(
            SuggestedOrder(
                symbol=instr.symbol,
                side=instr.side,
                volume=vol,
            )
        )
    return orders


--- src\tycherion\application\services\order_planner.py:END ---

--- src\tycherion\application\services\sizer.py:START ---
from __future__ import annotations
import MetaTrader5 as mt5

def symbol_min_volume(symbol: str) -> float:
    info = mt5.symbol_info(symbol)
    if not info:
        return 0.0
    v = max(info.volume_min, info.volume_step)
    steps = round(v / info.volume_step)
    return steps * info.volume_step

def volume_from_weight(symbol: str, weight: float, mode: str, fixed_volume: float) -> float:
    weight = max(0.0, min(1.0, float(weight)))
    if weight < 1e-6:
        return 0.0
    if mode == 'fixed':
        return float(fixed_volume) * weight
    return symbol_min_volume(symbol)


--- src\tycherion\application\services\sizer.py:END ---

--- src\tycherion\application\telemetry\event_factory.py:START ---
from __future__ import annotations

from datetime import datetime, timezone
from typing import Any, Mapping

from tycherion.ports.telemetry import TelemetryEvent, TelemetryLevel


def now_utc() -> datetime:
    return datetime.now(timezone.utc)


def make_event(
    *,
    run_id: str,
    name: str,
    level: str | TelemetryLevel,
    channel: str,
    scope: Mapping[str, Any] | None = None,
    payload: Mapping[str, Any] | None = None,
    schema_version: int = 1,
) -> TelemetryEvent:
    return TelemetryEvent(
        ts_utc=now_utc(),
        run_id=str(run_id),
        name=str(name),
        level=TelemetryLevel.coerce(level),
        channel=str(channel),
        scope=dict(scope or {}),
        payload=dict(payload or {}),
        schema_version=int(schema_version),
    )

--- src\tycherion\application\telemetry\event_factory.py:END ---

--- src\tycherion\application\telemetry\hub.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Iterable, Mapping

from tycherion.ports.telemetry import TelemetryEvent, TelemetryLevel, TelemetryPort, TelemetrySink


@dataclass(slots=True)
class TelemetryHub(TelemetryPort):
    """Fan-out hub.

    The hub is application-layer infrastructure: it receives canonical
    TelemetryEvent envelopes and forwards them to sinks. Sinks can filter
    independently.
    """

    sinks: list[TelemetrySink]
    base_scope: Mapping[str, Any] | None = None

    def emit(self, event: TelemetryEvent) -> None:
        scope = dict(self.base_scope or {})
        if event.scope:
            scope.update(dict(event.scope))
        merged = TelemetryEvent(
            ts_utc=event.ts_utc,
            run_id=event.run_id,
            name=event.name,
            level=event.level,
            channel=event.channel,
            scope=scope,
            payload=dict(event.payload or {}),
            schema_version=event.schema_version,
        )

        for s in list(self.sinks):
            try:
                if not s.enabled(merged.channel, merged.level, merged.name):
                    continue
                s.emit(merged)
            except Exception:
                # telemetry must never break the run
                continue

    def enabled(self, channel: str, level: str | TelemetryLevel) -> bool:
        lv = TelemetryLevel.coerce(level)
        for s in list(self.sinks):
            try:
                if s.enabled(str(channel), lv, None):
                    return True
            except Exception:
                continue
        return False

    def child(self, scope: Mapping[str, Any]) -> TelemetryPort:
        merged = dict(self.base_scope or {})
        merged.update(dict(scope or {}))
        return TelemetryHub(sinks=self.sinks, base_scope=merged)

    def flush(self) -> None:
        for s in list(self.sinks):
            flush = getattr(s, "flush", None)
            if callable(flush):
                try:
                    flush()
                except Exception:
                    continue

    def close(self) -> None:
        for s in list(self.sinks):
            close = getattr(s, "close", None)
            if callable(close):
                try:
                    close()
                except Exception:
                    continue

--- src\tycherion\application\telemetry\hub.py:END ---

--- src\tycherion\application\telemetry\run_context.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from typing import Any, Mapping

from tycherion.application.telemetry.event_factory import make_event
from tycherion.ports.telemetry import TelemetryLevel, TelemetryPort


@dataclass(frozen=True, slots=True)
class RunContext:
    run_id: str
    timeframe: str
    lookback_days: int
    started_utc: datetime
    config_hash: str | None = None


@dataclass(slots=True)
class RunTelemetry:
    """Ergonomic wrapper to produce consistent events for a single run_id."""

    port: TelemetryPort | None
    run_id: str
    base_scope: Mapping[str, Any] | None = None

    def enabled(self, channel: str, level: str | TelemetryLevel) -> bool:
        if self.port is None:
            return False
        return self.port.enabled(channel, level)

    def emit(
        self,
        *,
        name: str,
        channel: str,
        level: str | TelemetryLevel = TelemetryLevel.INFO,
        scope: Mapping[str, Any] | None = None,
        payload: Mapping[str, Any] | None = None,
        schema_version: int = 1,
    ) -> None:
        if self.port is None:
            return

        merged_scope = dict(self.base_scope or {})
        if scope:
            merged_scope.update(dict(scope))

        try:
            self.port.emit(
                make_event(
                    run_id=self.run_id,
                    name=name,
                    level=level,
                    channel=channel,
                    scope=merged_scope,
                    payload=payload,
                    schema_version=schema_version,
                )
            )
        except Exception:
            # never break the run due to telemetry
            return

    def child(self, scope: Mapping[str, Any]) -> "RunTelemetry":
        merged = dict(self.base_scope or {})
        merged.update(dict(scope or {}))
        return RunTelemetry(port=self.port, run_id=self.run_id, base_scope=merged)

--- src\tycherion\application\telemetry\run_context.py:END ---

--- src\tycherion\application\telemetry\__init__.py:START ---
from .event_factory import make_event
from .hub import TelemetryHub
from .run_context import RunContext, RunTelemetry

__all__ = [
    "make_event",
    "TelemetryHub",
    "RunContext",
    "RunTelemetry",
]

--- src\tycherion\application\telemetry\__init__.py:END ---

--- src\tycherion\bootstrap\main.py:START ---
from __future__ import annotations

import MetaTrader5 as mt5
from pathlib import Path

from tycherion.shared.config import load_config, AppConfig
from tycherion.adapters.mt5.market_data_mt5 import MT5MarketData
from tycherion.adapters.mt5.trading_mt5 import MT5Trader
from tycherion.adapters.mt5.account_mt5 import MT5Account
from tycherion.adapters.mt5.universe_mt5 import MT5Universe

from tycherion.adapters.telemetry.db_journal import DbExecutionJournalSink
from tycherion.adapters.telemetry.console import ConsoleTelemetrySink
from tycherion.application.telemetry.hub import TelemetryHub

from tycherion.application.plugins import registry as _registry
from tycherion.application.pipeline.service import ModelPipelineService
from tycherion.application.runmodes.live_multimodel import run_live_multimodel


def _ensure_initialized(cfg: AppConfig) -> None:
    if not mt5.initialize(path=cfg.mt5.terminal_path or None):
        raise SystemExit(f"MT5 initialize failed: {mt5.last_error()}")
    if cfg.mt5.login and cfg.mt5.password and cfg.mt5.server:
        if not mt5.login(
            login=int(cfg.mt5.login),
            password=cfg.mt5.password,
            server=cfg.mt5.server,
        ):
            raise SystemExit(f"MT5 login failed: {mt5.last_error()}")


def run_app(config_path: str) -> None:
    cfg = load_config(config_path)

    # Telemetry must be available as early as possible (e.g. plugin discovery).
    telemetry = _build_telemetry(cfg, config_path)

    # Discover all indicators, models, allocators and balancers
    _registry.auto_discover(telemetry)

    _ensure_initialized(cfg)
    try:
        market_data = MT5MarketData()
        trader = MT5Trader(
            dry_run=cfg.trading.dry_run,
            require_demo=cfg.trading.require_demo,
            deviation_points=cfg.trading.deviation_points,
            volume_mode=cfg.trading.volume_mode,
            fixed_volume=cfg.trading.fixed_volume,
        )
        account = MT5Account()
        universe = MT5Universe()

        pipeline_service = ModelPipelineService(
            market_data=market_data,
            model_registry=_registry.MODELS,
            indicator_picker=_registry.pick_indicator_for,
            timeframe=cfg.timeframe,
            lookback_days=cfg.lookback_days,
            playbook=cfg.application.playbook,
            telemetry=telemetry,
        )

        run_mode = (cfg.application.run_mode.name or "").lower()
        if run_mode == "live_multimodel":
            run_live_multimodel(cfg, trader, account, universe, pipeline_service, telemetry=telemetry)
        else:
            raise SystemExit(f"Unknown run_mode: {run_mode}")
    finally:
        try:
            telemetry.close()
        except Exception:
            pass
        mt5.shutdown()

def _build_telemetry(cfg: AppConfig, config_path: str) -> TelemetryHub:
    sinks = []
    telemetry_cfg = cfg.telemetry


    if bool(telemetry_cfg.db_enabled):
        sinks.append(
            DbExecutionJournalSink(
                db_path=str(telemetry_cfg.db_path or ''),
                enabled_flag=True,
                channels=set(telemetry_cfg.db_channels or ["audit", "ops"]),
                min_level=telemetry_cfg.db_min_level,
                batch_size=int(telemetry_cfg.db_batch_size or 50),
            )
        )

    if bool(telemetry_cfg.console_enabled):
        sinks.append(
            ConsoleTelemetrySink(
                enabled_flag=True,
                channels=set(telemetry_cfg.console_channels or ["ops"]),
                min_level=telemetry_cfg.console_min_level,
            )
        )

    return TelemetryHub(sinks=sinks)


--- src\tycherion\bootstrap\main.py:END ---

--- src\tycherion\domain\__init__.py:START ---


--- src\tycherion\domain\__init__.py:END ---

--- src\tycherion\domain\market\entities.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import NewType

Symbol = NewType("Symbol", str)


class AssetClass(str, Enum):
    EQUITY = "equity"
    FUTURE = "future"
    FX = "fx"
    OTHER = "other"


@dataclass
class Instrument:
    """Domain representation of a tradable instrument (stock, future, FX, etc.)."""

    symbol: Symbol
    asset_class: AssetClass
    currency: str
    lot_size: float
    min_volume: float
    volume_step: float


@dataclass
class Bar:
    """Minimal OHLCV bar used by indicators and models when not using DataFrame."""

    symbol: Symbol
    time: datetime
    open: float
    high: float
    low: float
    close: float
    volume: float

--- src\tycherion\domain\market\entities.py:END ---

--- src\tycherion\domain\market\__init__.py:START ---


--- src\tycherion\domain\market\__init__.py:END ---

--- src\tycherion\domain\portfolio\entities.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict


Symbol = str


@dataclass
class Signal:
    """Per-symbol signal produced by the models/ensemble.

    signed: desired direction/intensity in [-1, 1]
    confidence: optional confidence level in [0, 1]
    """

    symbol: Symbol
    signed: float
    confidence: float = 1.0


SignalsBySymbol = Dict[Symbol, Signal]


@dataclass
class Position:
    """Domain-level position in a single instrument.

    quantity: number of shares/contracts/etc.
    price: best available price estimate (e.g. last close or avg price).
    """

    symbol: Symbol
    quantity: float
    price: float


@dataclass
class PortfolioSnapshot:
    """Portfolio snapshot used by allocators/balancers at the domain level.

    Equity is the current account equity in account currency.
    """

    equity: float
    positions: Dict[Symbol, Position]

    def weight_of(self, symbol: Symbol) -> float:
        pos = self.positions.get(symbol)
        if not pos or self.equity <= 0:
            return 0.0
        return float(pos.quantity * pos.price) / float(self.equity)


@dataclass
class TargetAllocation:
    """Target portfolio allocation expressed as weights per symbol in [-1, 1].

    Positive weights are long exposure, negative weights are short exposure.
    """

    weights: Dict[Symbol, float]


@dataclass
class RebalanceInstruction:
    """Domain-level rebalance instruction expressed in weights, not broker
    volumes. Conversion to concrete order sizes happens in the application
    layer (order planner).
    """

    symbol: Symbol
    from_weight: float
    to_weight: float
    delta_weight: float
    side: str  # "BUY" | "SELL"

--- src\tycherion\domain\portfolio\entities.py:END ---

--- src\tycherion\domain\portfolio\__init__.py:START ---


--- src\tycherion\domain\portfolio\__init__.py:END ---

--- src\tycherion\domain\portfolio\allocators\base.py:START ---
from __future__ import annotations

from abc import ABC, abstractmethod

from tycherion.domain.portfolio.entities import SignalsBySymbol, TargetAllocation


class BaseAllocator(ABC):
    """Abstract base class for portfolio allocator plugins."""

    # Set by decorator
    name: str = ""
    tags: set[str] = set()

    @abstractmethod
    def allocate(self, signals: SignalsBySymbol) -> TargetAllocation:
        raise NotImplementedError

--- src\tycherion\domain\portfolio\allocators\base.py:END ---

--- src\tycherion\domain\portfolio\allocators\equal_weight.py:START ---
from __future__ import annotations

from tycherion.domain.portfolio.allocators.base import BaseAllocator
from tycherion.application.plugins.registry import register_allocator
from tycherion.domain.portfolio.entities import SignalsBySymbol, TargetAllocation


@register_allocator(name="equal_weight", tags={"default"})
class EqualWeightAllocator(BaseAllocator):
    """
    Simple allocator: gives the same absolute weight to all symbols that have
    a non-zero signal. Longs get +w, shorts get -w, holds get 0.
    """
    def allocate(self, signals: SignalsBySymbol) -> TargetAllocation:
        nonzero = [s for s in signals.values() if abs(float(s.signed)) > 1e-6]
        if not nonzero:
            # nothing to do
            return TargetAllocation(weights={})

        w = 1.0 / float(len(nonzero))
        weights: dict[str, float] = {}
        for sig in signals.values():
            if sig.signed > 0:
                weights[sig.symbol] = w
            elif sig.signed < 0:
                weights[sig.symbol] = -w
            else:
                weights[sig.symbol] = 0.0
        return TargetAllocation(weights=weights)

--- src\tycherion\domain\portfolio\allocators\equal_weight.py:END ---

--- src\tycherion\domain\portfolio\allocators\proportional.py:START ---
from __future__ import annotations

from tycherion.domain.portfolio.allocators.base import BaseAllocator
from tycherion.application.plugins.registry import register_allocator
from tycherion.domain.portfolio.entities import SignalsBySymbol, TargetAllocation


@register_allocator(name="proportional", tags={"default"})
class ProportionalAllocator(BaseAllocator):
    """
    Allocator that gives each symbol a weight proportional to the absolute
    value of its signal. Signals are normalised so that the sum of absolute
    weights is 1. Longs get +w, shorts get -w.
    """
    def allocate(self, signals: SignalsBySymbol) -> TargetAllocation:
        total = sum(abs(float(s.signed)) for s in signals.values())
        if total <= 1e-9:
            return TargetAllocation(weights={})

        weights: dict[str, float] = {}
        for sig in signals.values():
            if sig.signed == 0:
                weights[sig.symbol] = 0.0
            else:
                frac = abs(float(sig.signed)) / total
                weights[sig.symbol] = frac if sig.signed > 0 else -frac
        return TargetAllocation(weights=weights)

--- src\tycherion\domain\portfolio\allocators\proportional.py:END ---

--- src\tycherion\domain\portfolio\allocators\__init__.py:START ---


--- src\tycherion\domain\portfolio\allocators\__init__.py:END ---

--- src\tycherion\domain\portfolio\balancers\base.py:START ---
from __future__ import annotations

from abc import ABC, abstractmethod

from tycherion.domain.portfolio.entities import (
    PortfolioSnapshot,
    TargetAllocation,
    RebalanceInstruction,
)


class BaseBalancer(ABC):
    """Abstract base class for portfolio balancer / rebalancer plugins."""

    # Set by decorator
    name: str = ""
    tags: set[str] = set()

    @abstractmethod
    def plan(
        self,
        portfolio: PortfolioSnapshot,
        target: TargetAllocation,
        threshold: float = 0.25,
    ) -> list[RebalanceInstruction]:
        raise NotImplementedError

--- src\tycherion\domain\portfolio\balancers\base.py:END ---

--- src\tycherion\domain\portfolio\balancers\threshold.py:START ---
from __future__ import annotations

from tycherion.domain.portfolio.balancers.base import BaseBalancer
from tycherion.application.plugins.registry import register_balancer
from tycherion.domain.portfolio.entities import (
    PortfolioSnapshot,
    TargetAllocation,
    RebalanceInstruction,
)


@register_balancer(name="threshold", tags={"default"})
class ThresholdBalancer(BaseBalancer):
    """
    Domain-level balancer: generates rebalance instructions whenever the
    difference between current and target weight is greater than or equal
    to a configured threshold.
    """
    def plan(
        self,
        portfolio: PortfolioSnapshot,
        target: TargetAllocation,
        threshold: float = 0.25,
    ) -> list[RebalanceInstruction]:
        threshold = max(0.0, min(1.0, float(threshold)))
        instructions: list[RebalanceInstruction] = []

        symbols = set(target.weights.keys()) | set(portfolio.positions.keys())
        for sym in sorted(symbols):
            current_w = float(portfolio.weight_of(sym))
            target_w = float(target.weights.get(sym, 0.0))
            delta = target_w - current_w
            if abs(delta) < threshold:
                continue
            side = "BUY" if delta > 0 else "SELL"
            instructions.append(
                RebalanceInstruction(
                    symbol=sym,
                    from_weight=current_w,
                    to_weight=target_w,
                    delta_weight=delta,
                    side=side,
                )
            )
        return instructions

--- src\tycherion\domain\portfolio\balancers\threshold.py:END ---

--- src\tycherion\domain\portfolio\balancers\__init__.py:START ---


--- src\tycherion\domain\portfolio\balancers\__init__.py:END ---

--- src\tycherion\domain\signals\entities.py:START ---
from __future__ import annotations

from dataclasses import dataclass, field
from typing import Dict, List


@dataclass
class IndicatorOutput:
    """Standard output of an indicator for a single symbol.

    - score: aggregated metric in [-1, 1] (by convention in this project)
    - features: extra numeric features that models may consume.
    """

    score: float
    features: Dict[str, float]


@dataclass
class ModelDecision:
    """Per-model decision for a single symbol.

    side: "BUY" | "SELL" | "HOLD"
    weight: relative intensity (usually in [0, 1])
    confidence: confidence level in [0, 1]
    """

    side: str
    weight: float
    confidence: float

@dataclass
class AggregatedDecision:
    """
    Decisão agregada (ensemble) de todos os models para um símbolo.

    side       -> direção final ("BUY"/"SELL"/"HOLD")
    weight     -> intensidade em [0, 1]
    confidence -> confiança em [0, 1]
    signed     -> direção * intensidade em [-1, 1]
    """
    side: str
    weight: float
    confidence: float
    signed: float


@dataclass
class ModelStageResult:
    """Result for a symbol at a specific model stage in the pipeline."""

    model_name: str
    score: float


@dataclass
class SymbolState:
    """Mutable per-symbol state that flows through the analysis pipeline.

    This is intentionally generic so we can reuse it for universe filters,
    macro models and per-symbol alpha models over time.
    """
    symbol: str
    is_held: bool = False      # True if the symbol is currently in the portfolio
    alive: bool = True         # If False and not held, the symbol can be dropped from the pipeline

    base_score: float = 0.0    # Optional starting score (e.g. from simple filters)
    sanity_score: float = 0.0  # Data-quality / tradability / liquidity score
    macro_score: float = 0.0   # Macro / regime score for this symbol
    alpha_score: float = 0.0   # Final alpha-like score, typically coming from signal models

    pipeline_results: List[ModelStageResult] = field(default_factory=list)

    notes: Dict[str, float] = field(default_factory=dict)


--- src\tycherion\domain\signals\entities.py:END ---

--- src\tycherion\domain\signals\__init__.py:START ---


--- src\tycherion\domain\signals\__init__.py:END ---

--- src\tycherion\domain\signals\indicators\base.py:START ---
from __future__ import annotations

from abc import ABC, abstractmethod
import pandas as pd

from tycherion.domain.signals.entities import IndicatorOutput


class BaseIndicator(ABC):
    """Abstract base class for indicator plugins."""

    # Set by decorator
    key: str = ""
    method: str = ""
    tags: set[str] = set()

    @abstractmethod
    def compute(self, df: pd.DataFrame) -> IndicatorOutput:
        raise NotImplementedError

--- src\tycherion\domain\signals\indicators\base.py:END ---

--- src\tycherion\domain\signals\indicators\stretch_zscore.py:START ---
from __future__ import annotations

from tycherion.domain.signals.indicators.base import BaseIndicator
import pandas as pd

from tycherion.application.plugins.registry import register_indicator
from tycherion.domain.signals.entities import IndicatorOutput


@register_indicator(key="stretch", method="zscore_20", tags={"default"})
class StretchZScore20(BaseIndicator):
    period = 20

    def compute(self, df: pd.DataFrame) -> IndicatorOutput:
        if df.empty or len(df) < self.period:
            return IndicatorOutput(score=0.0, features={})
        close = df["close"].astype(float)
        ma = close.rolling(self.period).mean()
        sd = close.rolling(self.period).std(ddof=0).replace(0, 1e-9)
        z = (close - ma) / sd
        zval = float(z.iloc[-1])
        score = max(-1.0, min(1.0, -zval / 3.0))
        return IndicatorOutput(score=score, features={"z": zval})

--- src\tycherion\domain\signals\indicators\stretch_zscore.py:END ---

--- src\tycherion\domain\signals\indicators\trend_donchian.py:START ---
from __future__ import annotations

from tycherion.domain.signals.indicators.base import BaseIndicator
import pandas as pd

from tycherion.application.plugins.registry import register_indicator
from tycherion.domain.signals.entities import IndicatorOutput


@register_indicator(key="trend", method="donchian_50_50", tags={"default"})
class TrendDonchian5050(BaseIndicator):
    high_n = 50
    low_n = 50

    def compute(self, df: pd.DataFrame) -> IndicatorOutput:
        if df.empty or len(df) < max(self.high_n, self.low_n):
            return IndicatorOutput(score=0.0, features={})
        hh = df["high"].rolling(self.high_n).max()
        ll = df["low"].rolling(self.low_n).min()
        mid = (hh + ll) / 2.0
        rng = (hh - ll).replace(0, 1e-9)
        pos = (df["close"] - mid) / (rng / 2.0)
        score = float(pos.iloc[-1])
        score = max(-1.0, min(1.0, score))
        return IndicatorOutput(
            score=score,
            features={"upper": float(hh.iloc[-1]), "lower": float(ll.iloc[-1])},
        )

--- src\tycherion\domain\signals\indicators\trend_donchian.py:END ---

--- src\tycherion\domain\signals\indicators\volatility_atr.py:START ---
from __future__ import annotations

from tycherion.domain.signals.indicators.base import BaseIndicator
import pandas as pd

from tycherion.application.plugins.registry import register_indicator
from tycherion.domain.signals.entities import IndicatorOutput


@register_indicator(key="volatility", method="atr_14", tags={"default"})
class VolATR14(BaseIndicator):
    period = 14

    def compute(self, df: pd.DataFrame) -> IndicatorOutput:
        if df.empty or len(df) < self.period + 1:
            return IndicatorOutput(score=0.0, features={})
        high = df["high"].astype(float)
        low = df["low"].astype(float)
        close = df["close"].astype(float)
        prev_close = close.shift(1)
        tr = (high - low).abs()
        tr = pd.concat(
            [tr, (high - prev_close).abs(), (low - prev_close).abs()], axis=1
        ).max(axis=1)
        atr = tr.rolling(self.period).mean()
        val = float(atr.iloc[-1])
        score = 1.0 / (1.0 + val) if val > 0 else 0.0
        return IndicatorOutput(score=score, features={"atr": val})

--- src\tycherion\domain\signals\indicators\volatility_atr.py:END ---

--- src\tycherion\domain\signals\indicators\__init__.py:START ---


--- src\tycherion\domain\signals\indicators\__init__.py:END ---

--- src\tycherion\domain\signals\models\base.py:START ---
from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Dict

from tycherion.domain.signals.entities import IndicatorOutput, ModelDecision


class SignalModel(ABC):
    """Abstract base class for per-symbol signal models."""

    name: str = ""
    tags: set[str] = set()

    @abstractmethod
    def requires(self) -> set[str]:
        raise NotImplementedError

    @abstractmethod
    def decide(self, indicators: Dict[str, IndicatorOutput]) -> ModelDecision:
        raise NotImplementedError

--- src\tycherion\domain\signals\models\base.py:END ---

--- src\tycherion\domain\signals\models\mean_reversion.py:START ---
from __future__ import annotations

from tycherion.domain.signals.models.base import SignalModel
from typing import Dict

from tycherion.application.plugins.registry import register_model
from tycherion.domain.signals.entities import IndicatorOutput, ModelDecision


@register_model(name="mean_reversion", tags={"default"})
class MeanReversion(SignalModel):
    def requires(self) -> set[str]:
        return {"stretch", "volatility"}

    def decide(self, indicators: Dict[str, IndicatorOutput]) -> ModelDecision:
        stretch = indicators.get("stretch") if indicators is not None else None
        z = float(stretch.features.get("z", 0.0)) if stretch else 0.0

        if z <= -2.0:
            w = min(1.0, abs(z) / 3.0)
            return ModelDecision(side="BUY", weight=w, confidence=0.6)
        if z >= 2.0:
            w = min(1.0, abs(z) / 3.0)
            return ModelDecision(side="SELL", weight=w, confidence=0.6)
        return ModelDecision(side="HOLD", weight=0.0, confidence=0.4)


--- src\tycherion\domain\signals\models\mean_reversion.py:END ---

--- src\tycherion\domain\signals\models\trend_following.py:START ---
from __future__ import annotations

from tycherion.domain.signals.models.base import SignalModel
from typing import Dict

from tycherion.application.plugins.registry import register_model
from tycherion.domain.signals.entities import IndicatorOutput, ModelDecision


@register_model(name="trend_following", tags={"default"})
class TrendFollowing(SignalModel):
    def requires(self) -> set[str]:
        return {"trend", "volatility"}

    def decide(self, indicators: Dict[str, IndicatorOutput]) -> ModelDecision:
        trend = indicators.get("trend") if indicators is not None else None
        tr = float(trend.score) if trend else 0.0

        if tr > 0.2:
            return ModelDecision(
                side="BUY",
                weight=min(1.0, 0.5 + tr * 0.5),
                confidence=0.7,
            )
        if tr < -0.2:
            return ModelDecision(
                side="SELL",
                weight=min(1.0, 0.5 + (-tr) * 0.5),
                confidence=0.7,
            )
        return ModelDecision(side="HOLD", weight=0.0, confidence=0.3)


--- src\tycherion\domain\signals\models\trend_following.py:END ---

--- src\tycherion\domain\signals\models\__init__.py:START ---


--- src\tycherion\domain\signals\models\__init__.py:END ---

--- src\tycherion\ports\account.py:START ---
from __future__ import annotations

from typing import Protocol, List

from tycherion.domain.portfolio.entities import Position


class AccountPort(Protocol):
    def is_demo(self) -> bool: ...
    def balance(self) -> float: ...
    def equity(self) -> float: ...
    def positions(self) -> List[Position]: ...

--- src\tycherion\ports\account.py:END ---

--- src\tycherion\ports\market_data.py:START ---
from __future__ import annotations
from typing import Protocol
from datetime import datetime
import pandas as pd

class MarketDataPort(Protocol):
    def get_bars(self, symbol: str, timeframe: str, start: datetime, end: datetime) -> pd.DataFrame: ...

--- src\tycherion\ports\market_data.py:END ---

--- src\tycherion\ports\telemetry.py:START ---
from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Any, Mapping, Protocol


class TelemetryLevel(str, Enum):
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARN = "WARN"
    ERROR = "ERROR"

    @classmethod
    def coerce(cls, value: str | "TelemetryLevel") -> "TelemetryLevel":
        if isinstance(value, TelemetryLevel):
            return value
        v = (value or "INFO").upper().strip()
        try:
            return TelemetryLevel(v)
        except Exception:
            return TelemetryLevel.INFO

    def rank(self) -> int:
        order = {
            TelemetryLevel.DEBUG: 10,
            TelemetryLevel.INFO: 20,
            TelemetryLevel.WARN: 30,
            TelemetryLevel.ERROR: 40,
        }
        return int(order[self])


@dataclass(frozen=True, slots=True)
class TelemetryEvent:
    """Canonical, small telemetry envelope.

    NOTE: `scope` and `payload` must be JSON-serialisable.
    """

    ts_utc: datetime
    run_id: str
    name: str
    level: TelemetryLevel
    channel: str
    scope: Mapping[str, Any] | None
    payload: Mapping[str, Any]
    schema_version: int = 1


class TelemetrySink(Protocol):
    """Adapter-side sink.

    A sink can filter independently. The hub will call `enabled` to determine
    whether some payload should be built (gating), then `emit` to persist/print.
    """

    def enabled(self, channel: str, level: TelemetryLevel, name: str | None = None) -> bool: ...

    def emit(self, event: TelemetryEvent) -> None: ...


class TelemetryPort(Protocol):
    """Application-facing telemetry API (fan-out hub + scoped wrappers)."""

    def emit(self, event: TelemetryEvent) -> None: ...

    def enabled(self, channel: str, level: str | TelemetryLevel) -> bool: ...

    def child(self, scope: Mapping[str, Any]) -> "TelemetryPort": ...

--- src\tycherion\ports\telemetry.py:END ---

--- src\tycherion\ports\trading.py:START ---
from __future__ import annotations
from dataclasses import dataclass
from typing import Protocol, Optional

@dataclass
class TradeResult:
    ok: bool
    retcode: int
    order: Optional[int]
    message: str

class TradingPort(Protocol):
    def market_buy(self, symbol: str, volume: Optional[float] = None) -> TradeResult: ...
    def market_sell(self, symbol: str, volume: Optional[float] = None) -> TradeResult: ...

--- src\tycherion\ports\trading.py:END ---

--- src\tycherion\ports\universe.py:START ---
from __future__ import annotations
from typing import Protocol, List

class UniversePort(Protocol):
    def visible_symbols(self) -> List[str]: ...
    def by_pattern(self, pattern: str) -> List[str]: ...

--- src\tycherion\ports\universe.py:END ---

--- src\tycherion\shared\config.py:START ---
from __future__ import annotations
from pydantic import BaseModel, field_validator
from typing import Optional, Any
import os, yaml
from dotenv import load_dotenv

class Trading(BaseModel):
    dry_run: bool = True
    require_demo: bool = True
    deviation_points: int = 10
    volume_mode: str = "min"     # 'min' | 'fixed'
    fixed_volume: float = 0.01

class Risk(BaseModel):
    risk_per_trade_pct: float = 0.5
    max_daily_loss_pct: float = 2.0

class MT5(BaseModel):
    terminal_path: Optional[str] = None
    server: Optional[str] = None
    login: Optional[int] = None
    password: Optional[str] = None

class RunMode(BaseModel):
    name: str = "live_multimodel"

class ScheduleCfg(BaseModel):
    run_forever: bool = False
    interval_seconds: int = 60

class CoverageCfg(BaseModel):
    source: str = "market_watch"
    symbols: list[str] = []
    pattern: str | None = None


class PipelineStageCfg(BaseModel):
    """Configuration of a single stage in the model pipeline."""

    name: str
    drop_threshold: float | None = None


class ModelsCfg(BaseModel):
    """Application-level model selection.

    `pipeline` defines an ordered list of models to run per symbol. The order
    is the order of execution. Each stage can optionally define a
    `drop_threshold` used to discard non-held symbols early.
    """

    pipeline: list[PipelineStageCfg] = []

    @field_validator("pipeline", mode="before")
    @classmethod
    def _coerce_pipeline(cls, v: Any):
        # Accept both:
        # - pipeline: ["trend_following", "mean_reversion"]
        # - pipeline: [{name: "...", drop_threshold: ...}, ...]
        if v is None:
            return []
        if isinstance(v, list):
            out: list[Any] = []
            for item in v:
                if isinstance(item, str):
                    out.append({"name": item})
                else:
                    out.append(item)
            return out
        return v


class PortfolioCfg(BaseModel):
    allocator: str = "proportional"     # plugin name
    balancer: str = "threshold"         # plugin name
    threshold_weight: float = 0.25      # only rebalance if |w| >= threshold

class ApplicationCfg(BaseModel):
    run_mode: RunMode = RunMode()
    playbook: str = "default"
    schedule: ScheduleCfg = ScheduleCfg()
    coverage: CoverageCfg = CoverageCfg()
    models: ModelsCfg = ModelsCfg()
    portfolio: PortfolioCfg = PortfolioCfg()


class TelemetrySinkCfg(BaseModel):
    enabled: bool = True
    channels: list[str] = ["audit", "ops"]
    min_level: str = "INFO"  # DEBUG/INFO/WARN/ERROR


class TelemetryCfg(BaseModel):
    """Telemetry configuration (bootstrap/application concern, not domain)."""

    # DB execution journal
    db_enabled: bool = True
    db_path: Optional[str] = None
    db_channels: list[str] = ["audit", "ops"]
    db_min_level: str = "INFO"
    db_batch_size: int = 50

    # Console sink
    console_enabled: bool = False
    console_channels: list[str] = ["ops"]
    console_min_level: str = "INFO"


class AppConfig(BaseModel):
    timeframe: str
    lookback_days: int
    trading: Trading = Trading()
    risk: Risk = Risk()
    mt5: MT5 = MT5()
    application: ApplicationCfg = ApplicationCfg()
    telemetry: TelemetryCfg = TelemetryCfg()

def load_config(path: str) -> AppConfig:
    load_dotenv(override=False)
    import pathlib
    p = pathlib.Path(path)
    if not p.exists():
        raise FileNotFoundError(f"Config not found: {path}")
    with open(path, "r", encoding="utf-8") as f:
        raw = yaml.safe_load(f) or {}
    raw.setdefault("mt5", {})
    mt5_cfg = raw["mt5"] or {}

    def coalesce(yaml_val, env_val):
        return env_val if (yaml_val in (None, "", 0) and env_val not in (None, "")) else yaml_val

    env_terminal = os.getenv("MT5_TERMINAL_PATH")
    env_server   = os.getenv("MT5_SERVER")
    env_login    = os.getenv("MT5_LOGIN")
    env_pass     = os.getenv("MT5_PASSWORD")

    mt5_cfg["terminal_path"] = coalesce(mt5_cfg.get("terminal_path"), env_terminal)
    mt5_cfg["server"]        = coalesce(mt5_cfg.get("server"),        env_server)
    mt5_cfg["login"]         = coalesce(mt5_cfg.get("login"),         int(env_login) if env_login and env_login.isdigit() else None)
    mt5_cfg["password"]      = coalesce(mt5_cfg.get("password"),      env_pass)

    raw["mt5"] = mt5_cfg
    return AppConfig.model_validate(raw)

--- src\tycherion\shared\config.py:END ---

--- src\tycherion\shared\decorators.py:START ---
from __future__ import annotations
from functools import wraps
import logging
import MetaTrader5 as mt5

_log = logging.getLogger(__name__)

def demo_only(fn):
    @wraps(fn)
    def wrapper(self, *args, **kwargs):
        require = getattr(self, "require_demo", True)
        if require:
            ai = mt5.account_info()
            if not ai or ai.trade_mode != mt5.ACCOUNT_TRADE_MODE_DEMO:
                raise RuntimeError("Blocked: only allowed in DEMO account.")
        return fn(self, *args, **kwargs)
    return wrapper

def logged(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        name = fn.__qualname__
        try:
            res = fn(*args, **kwargs)
            _log.debug("%s: ok -> %s", name, res)
            return res
        except Exception as e:
            _log.exception("%s: error", name)
            raise
    return wrapper

--- src\tycherion\shared\decorators.py:END ---

--- tests\test_telemetry.py:START ---
from __future__ import annotations

import unittest
from datetime import datetime, timezone

import pathlib
import sys

ROOT = pathlib.Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT / "src"))

import pandas as pd

from tycherion.application.pipeline.config import PipelineConfig, PipelineStageConfig
from tycherion.application.pipeline.service import ModelPipelineService
from tycherion.application.telemetry.hub import TelemetryHub
from tycherion.adapters.telemetry.memory import InMemoryTelemetrySink
from tycherion.domain.portfolio.entities import PortfolioSnapshot
from tycherion.domain.signals.entities import ModelDecision
from tycherion.domain.signals.models.base import SignalModel
from tycherion.ports.telemetry import TelemetryLevel


class TestTelemetryHub(unittest.TestCase):
    def test_enabled_any_sink_accepts(self) -> None:
        sink = InMemoryTelemetrySink(
            enabled_flag=True,
            channels={"debug"},
            min_level=TelemetryLevel.DEBUG,
        )
        hub = TelemetryHub(sinks=[sink])

        self.assertTrue(hub.enabled("debug", "DEBUG"))
        self.assertFalse(hub.enabled("audit", "INFO"))


class _DummyMarketData:
    def get_bars(self, symbol: str, timeframe: str, start: datetime, end: datetime) -> pd.DataFrame:
        _ = (symbol, timeframe, start, end)
        # Minimal but realistic-ish OHLC frame
        return pd.DataFrame(
            {
                "time": [datetime(2020, 1, 1, tzinfo=timezone.utc)],
                "open": [1.0],
                "high": [1.0],
                "low": [1.0],
                "close": [1.0],
                "tick_volume": [1],
            }
        )


class _DummyModel(SignalModel):
    def requires(self) -> set[str]:
        return set()

    def decide(self, indicators):  # type: ignore[override]
        _ = indicators
        return ModelDecision(side="BUY", weight=0.5, confidence=0.1)


class TestDebugGating(unittest.TestCase):
    def test_debug_events_not_emitted_when_debug_disabled(self) -> None:
        sink = InMemoryTelemetrySink(
            enabled_flag=True,
            channels={"audit", "ops"},
            min_level=TelemetryLevel.INFO,
        )
        hub = TelemetryHub(sinks=[sink])

        svc = ModelPipelineService(
            market_data=_DummyMarketData(),
            model_registry={"dummy": _DummyModel()},
            indicator_picker=lambda key, pb: None,  # type: ignore[return-value]
            timeframe="D1",
            lookback_days=10,
            playbook=None,
            telemetry=hub,
        )

        pipeline_config = PipelineConfig(stages=[PipelineStageConfig(name="dummy", drop_threshold=None)])
        portfolio = PortfolioSnapshot(equity=1000.0, positions={})

        svc.run(
            universe_symbols=["AAA"],
            portfolio_snapshot=portfolio,
            pipeline_config=pipeline_config,
            run_id="test-run",
        )

        self.assertTrue(len(sink.events) > 0)
        self.assertEqual(0, sum(1 for e in sink.events if e.channel == "debug"))


if __name__ == "__main__":
    unittest.main()

--- tests\test_telemetry.py:END ---
